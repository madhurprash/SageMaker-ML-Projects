{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2bf18a7-f73d-42f8-93e1-c30b0e86a69e",
   "metadata": {},
   "source": [
    "## Security Engineer SlackBot: LLM + RETREIVAL AUGMENTED GENERATION\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "Currently, the appsec team has done good job in creating a knowledgeable for frequently asked question from service team. So, whenever a service team reach out to Individual security team member individually or in a slack group with a question that exist in the knowledge base(that security team maintains). Security team do a manual cross reference for that question in the quip doc and respond to the service team in slack with an answer. The process is good in a way that the security team doesn’t need to spend time looking out for answer for the question if it exists. However, the process of responding to service team member is still manual. It requires security team member attention and a context switch from what they currently work upon to respond to the question which has been responded earlier.\n",
    "\n",
    "\n",
    "\n",
    "#### Proposed Solution\n",
    "\n",
    "Security team is coming up with a solution which can automate and help answer the frequently asked questions from service team. There is reliance on the knowledge base and if the answer to a question exists in the knowledge base we inherently assume that the question has been asked earlier. \n",
    "\n",
    "*Note*: Process of building knowledge base is currently out of scope of this project. There is already work going on maturing the knowledge base. This project will leverage the KB to automate the response of a frequently asked question by service team in a slack message.\n",
    "\n",
    "#### STEPS:\n",
    "\n",
    "1. Build, train and deploy the model from the HuggingFace pretrained model library.\n",
    "\n",
    "2. Create a knowledge base to fine tune a pretrained model from hugging face\n",
    "\n",
    "3. Use the finetuned model to generate text responses to questions by customers.\n",
    "\n",
    "#### AI/ML solution by: Madhur Prashant (Alias: madhurpt, madhurpt@amazon.com)\n",
    "\n",
    "## Retrieval Augmented Generation (RAG) with Lanchain\n",
    "\n",
    "1. Langchain: Framework for orchestrating the RAG Workflow\n",
    "2. FAISS: Using an in-memory vector database for storing document embeddings\n",
    "3. PyPDF: Python library for processing and storing the PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f00955-c767-4ec5-8cf3-0fe59e3ee7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.251 --quiet --root-user-action=ignore\n",
    "%pip install faiss-cpu==1.7.4 --quiet --root-user-action=ignore\n",
    "%pip install pypdf==3.15.1 --quiet --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a3417-1848-4158-8a25-f7f946335d54",
   "metadata": {},
   "source": [
    "### FETCHING AND PROCESSING THE AppSec Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd61df8-639d-49bc-b105-57536d1d4e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    'General AppSec Related.pdf',\n",
    "]\n",
    "\n",
    "data_root = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f1848a-0946-4b1c-b28b-abfd9822ba41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Document Pages: 28\n",
      "Number of Document Chunks: 170\n"
     ]
    }
   ],
   "source": [
    "filenames = [\n",
    "    'General AppSec Related.pdf',\n",
    "]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in filenames:\n",
    "    loader = PyPDFLoader(data_root + filename)\n",
    "    loaded_documents = loader.load()  # Use a variable to store loaded documents\n",
    "    documents.extend(loaded_documents)  # Extend the list with loaded documents\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'Number of Document Pages: {len(documents)}')\n",
    "print(f'Number of Document Chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c36c07-c8bb-4a98-affc-6c0ed429d5fc",
   "metadata": {},
   "source": [
    "### Now, that we have processed the document or data, let's work with the model to embed the documents in vector stores to be able to use RAG to get the contextually correct AppSec related documents\n",
    "\n",
    "## Deploying a Model for Embedding: All MiniLML6 v2 and the LLaMa-2-7b-chat for our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c22367-9375-4bb0-913e-bc0893d0fffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "    sagemaker \\\n",
    "    pinecone-client==2.2.1 \\\n",
    "    ipywidgets==7.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d8afb-036a-4237-8a4d-b1115df8482d",
   "metadata": {},
   "source": [
    "To begin, we will initialize all of the SageMaker session variables we'll need to use throughout the walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5881349-b263-4143-8e25-034a3cf3351e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "my_model = JumpStartModel(model_id = \"meta-textgeneration-llama-2-7b-f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1d2a4-b05d-4ee0-b7bf-e2c87b46a2f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LLaMa chat LLM endpoint: arn:aws:sagemaker:us-east-1:110011534045:endpoint-config/llama-2-generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d950707-3569-4d43-8e5a-f687aa147127",
   "metadata": {},
   "source": [
    "## Deploying the model endpoint for Sentence Transformer embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295653ef-0f2f-4d5a-9f81-8b035def79ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hub_config = {\n",
    "#     \"HF_MODEL_ID\": \"sentence-transformers/all-MiniLM-L6-v2\",  # model_id from hf.co/models\n",
    "#     \"HF_TASK\": \"feature-extraction\",\n",
    "# }\n",
    "\n",
    "# huggingface_model = HuggingFaceModel(\n",
    "#     env=hub_config,\n",
    "#     role=role,\n",
    "#     transformers_version=\"4.6\",  # transformers version used\n",
    "#     pytorch_version=\"1.7\",  # pytorch version used\n",
    "#     py_version=\"py36\",  # python version of the DLC\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b132d2a-7237-4838-b1a8-4b9c4bf7de78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\"\n",
    "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
    "embedding_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcf0b5f-ddc6-4058-9986-d5c0db0a6db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hf-textembedding-all-minilm-l6-v2-2023-09-04-19-33-04-133'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
    "embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ebdfe3-e09f-48ba-be85-e26c453571c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "print(aws_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da5a52-e599-449e-a001-a6a3c9296035",
   "metadata": {},
   "source": [
    "## Creating and Populating our Vector Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d924b28-9091-4d58-8e61-69f0103cf3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        embeddings = response_json.get(\"embedding\", [])  # Use get() with a default value\n",
    "        return embeddings  # Make sure to return the embeddings\n",
    "    \n",
    "\n",
    "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name= embedding_model_endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffa506-6579-49ef-8704-a91c940d3c14",
   "metadata": {},
   "source": [
    "Now, with our embeddings, we can process our document chunks into vectors and actually store them somewhere. Our project will use the:\n",
    "\n",
    "#### FAISS: In-Memory vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d321bbaf-bc67-4696-bec4-4f154291b123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c3c446-1bc2-4352-9b67-e69d71aee487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4b99b-f0a8-4c84-9931-444d9047c194",
   "metadata": {},
   "source": [
    "#### Now, we will store our FAISS database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b44801c9-919a-4e01-8c4a-c57f170e4bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2da94-a63c-4f2d-ad10-116fed4639fd",
   "metadata": {},
   "source": [
    "### NOW, RUNNING VECTOR QUERIES!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64dcf43-be7b-43f6-b751-de443910f685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is penetration testing?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622bb635-5f35-48e2-a53c-cfa15011f134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: customers expect our products, services, and systems to be hardened and a\n",
      "critical check that we've met this expectation is a pen test.\n",
      "Penetration testing complements earlier-lifecycle activities such as design\n",
      "reviews, threat modeling, code reviews for security, and security unit and\n",
      "integration testing. Ideally, these earlier-lifecycle activities would obviate the\n",
      "need for a pen test but our experience has shown that this late-lifecycle\n",
      "Score 0.6931231021881104\n",
      "\n",
      "\n",
      "Content: Status of this Document\n",
      "This is a living document and will be updated as our criteria and process\n",
      "improve. Unless you are making cosmetic changes, please work with subur@.\n",
      "Why Do A Penetration Test?\n",
      "Penetration testing, or simulating how a malicious actor could try to misuse\n",
      "our systems, is an essential security activity to validate that what has been\n",
      "built meets our high security bar and will protect customers and AWS. Our\n",
      "customers expect our products, services, and systems to be hardened and a\n",
      "Score 0.7269995808601379\n",
      "\n",
      "\n",
      "Content: Apollo, etc.).\n",
      "WHEN PENETRATION TESTING IS REQUIRED\n",
      "VERIFY WITH THE SERVICE TEAM IF THE PENTESTER NEEDS ANY SPECIALIZED PERMISSION TO ACCESS THE\n",
      "TESTING ENVIRONMENT, LIKE PROD ACCESS, MIDWAY-CHN, ETC\n",
      "PRE-LAUNCH PENETRATION TESTING IS REQUIRED FOR...\n",
      "●\n",
      "●\n",
      "●\n",
      "●\n",
      "●\n",
      "○\n",
      "○New externally-facing services, features, or infrastructure\n",
      "New security-sensitive internal services or infrastructure\n",
      "Externally-facing services, features, or infrastructure that have not been tested in the last 6 months, however minor the\n",
      "Score 0.7833014726638794\n",
      "\n",
      "\n",
      "Content: customers) OR\n",
      "Contains information about the security state of services OR\n",
      "Contains payment/billing information OR\n",
      "Handles payments, money, or cash equivalents OR\n",
      "Contains data deemed sensitive by the engineer and service team OR\n",
      "Brokers authentication, authorization, or provides other security functions for services OR\n",
      "Is a direct dependency of critical external and internal AWS services (Billing and Payments, S3, EC2, Brazil,\n",
      "Apollo, etc.).\n",
      "WHEN PENETRATION TESTING IS REQUIRED\n",
      "Score 0.9676523208618164\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nScore {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be807edd-99d3-400f-951b-c2e29e95965e",
   "metadata": {},
   "source": [
    "## PROMPT ENGINEERING FOR CUSTOM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3af26f7f-217c-40ef-813a-830bf6e76a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Use the context provided below to answer the question at the end. If you don't know the answer, please state that you don't know and do not attempt to make up an answer.\n",
    "<</SYS>>\n",
    "\n",
    "Context:\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad12c31-4a25-4cb4-9485-40eb3de21a2c",
   "metadata": {},
   "source": [
    "#### Now that we have defined what our prompt template is going to look like, we will create and prepare our LLM\n",
    "\n",
    "## PREPARING OUR CUSTOM LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfa95326-228a-4f79-ad5e-9db54fec3ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain import SagemakerEndpoint, PromptTemplate\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "import json\n",
    "\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            {\"inputs\" : [\n",
    "                [\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ]], \n",
    "             \"parameters\": {**model_kwargs}\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generation\"][\"content\"]\n",
    "    \n",
    "qa_content_handler = QAContentHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd094af-d0dc-4497-ac96-734edf83710e",
   "metadata": {},
   "source": [
    "Now that we have our content handler, we will deploy a sagemaker endpoint for our Large Language Model that will work with the embedding model to generate outputs.\n",
    "\n",
    "## SageMaker LLaMa-2-7b-f LLM for our CUSTOM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2be66223-48fb-480e-8638-0dcf08a5f939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"*\"\n",
    "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
    "llm_predictor = llm_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.g5.4xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "baba9f1d-df41-46c2-b9f7-8f49dd695deb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-textgeneration-llama-2-7b-f-2023-09-04-19-49-48-116'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
    "llm_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "973efbe4-5503-4264-b8e7-07f28d2eb2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=llm_model_endpoint_name, \n",
    "    region_name=aws_region, \n",
    "    model_kwargs={\"max_new_tokens\": 1000, \"top_p\":0.9, \"temperature\": 1e-11}, \n",
    "    endpoint_kwargs={\"CustomAttributes\": \"accept_eula=true\"},\n",
    "    content_handler=qa_content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b329265-8dac-4722-bb4e-e026f9669e9a",
   "metadata": {},
   "source": [
    "Now, we can use our 'llm' object to query and make predictions on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc442cf0-45f1-4473-a089-245142dbac59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hello\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "409feaa9-5227-4bbe-9150-033d8c9d6b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Penetration testing, also known as pen testing or ethical hacking, is a cybersecurity assessment where a trained security professional simulates a cyber attack on an organization's computer systems, network, or web application to identify vulnerabilities and weaknesses. The goal of penetration testing is to help organizations strengthen their defenses and protect against real-world attacks.\\n\\nIn the context of Amazon Web Services (AWS), penetration testing can be performed on AWS resources and infrastructure to identify potential security risks and weaknesses. This can include testing the security of AWS services such as EC2 instances, RDS instances, S3 buckets, and Lambda functions, as well as the security of the network connectivity between these resources.\\n\\nPenetration testing in AWS typically involves the following steps:\\n\\n1. Planning and preparation: The security professional will work with the organization to identify the scope of the test, the systems and resources to be tested, and the goals of the test.\\n2. Information gathering: The security professional will gather information about the target systems and resources, including network topology, system configurations, and vulnerability information.\\n3. Vulnerability identification: The security professional will identify potential vulnerabilities in the target systems and resources, using automated tools and manual techniques.\\n4. Exploitation: The security professional will attempt to exploit identified vulnerabilities to gain unauthorized access to the target systems and resources.\\n5. Post-exploitation: The security professional will analyze the systems and resources that have been compromised to determine the extent of the attack and the data that can be accessed.\\n6. Reporting: The security professional will document the findings of the test, including any vulnerabilities identified and exploited, and provide recommendations for remediation.\\n\\nPenetration testing can be performed in various ways, including:\\n\\n1. Network penetration testing: This involves testing the security of the network connectivity between systems and resources, as well as the security of the network itself.\\n2. Web application penetration testing: This involves testing the security of web applications and the vulnerabilities they may have.\\n3. Social engineering penetration testing: This involves testing the security of human factors, such as the susceptibility of employees to phishing attacks or other social engineering tactics.\\n4. Wireless penetration testing: This involves testing the security of wireless networks and the devices connected to them.\\n\\nPenetration testing can help organizations identify and remediate security vulnerabilities before they can be exploited by attackers. It can also help organizations meet compliance requirements and demonstrate due diligence in protecting their systems and data.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is penetration testing in AWS?\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1f79a-e0e2-4c56-bd3d-e9bb534cd801",
   "metadata": {},
   "source": [
    "## Not a bad answer, but we will create an Langchain CHAIN  using the RetrievalQA chain which will:\n",
    "\n",
    "1. Take a query as input\n",
    "2. Generate query embeddings\n",
    "3. Query the vector database for revelant chunks from the knowledge you supply\n",
    "4. Inject the context and original query in the Prompt Template\n",
    "5. Invoke the LLM with a completed prompt and\n",
    "6. Successfuly get the LLM Response/Completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bf0182a-a251-4810-9492-fba417c4d2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type = 'stuff',\n",
    "    retriever=db.as_retriever(), \n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs={\"prompt\":PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca30276-cf0e-4e8f-8e6c-6112cb05bf49",
   "metadata": {},
   "source": [
    "### Now that our chain has been created, we can supply queries to it and generate responses based on our source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9a80a62-b70d-41b4-a44f-caf00b47f554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is penetration testing in AWS Security?\n",
      "\n",
      "Result:  Based on the provided context, penetration testing in AWS Security refers to the process of simulating attacks on an AWS system or application to identify vulnerabilities and weaknesses, and to validate the effectiveness of the security controls in place. The purpose of penetration testing is to ensure that the system or application meets the required security standards and can protect against potential threats.\n",
      "\n",
      "The document provides criteria for determining when penetration testing is required, which includes:\n",
      "\n",
      "1. When a new feature or functionality meets the conditions in criterion 5 of the Penetration Testing Criteria.\n",
      "2. If you are concerned about the scalability or sustainability of these security review criteria, please discuss them with your AWS security engineer or AWS security manager.\n",
      "\n",
      "The document also provides a PT determination criteria and a PT scoping template to help identify the assets that require penetration testing and to scope the testing activities.\n",
      "\n",
      "Overall, penetration testing in AWS Security is an essential security activity that helps to ensure the security and integrity of the systems and applications in the AWS environment.\n",
      "\n",
      "Context Documents: \n",
      "page_content='Status of this Document\\nThis is a living document and will be updated as our criteria and process\\nimprove. Unless you are making cosmetic changes, please work with subur@.\\nWhy Do A Penetration Test?\\nPenetration testing, or simulating how a malicious actor could try to misuse\\nour systems, is an essential security activity to validate that what has been\\nbuilt meets our high security bar and will protect customers and AWS. Our\\ncustomers expect our products, services, and systems to be hardened and a' metadata={'source': './data/General AppSec Related.pdf', 'page': 22}\n",
      "\n",
      "page_content='customers) OR\\nContains information about the security state of services OR\\nContains payment/billing information OR\\nHandles payments, money, or cash equivalents OR\\nContains data deemed sensitive by the engineer and service team OR\\nBrokers authentication, authorization, or provides other security functions for services OR\\nIs a direct dependency of critical external and internal AWS services (Billing and Payments, S3, EC2, Brazil,\\nApollo, etc.).\\nWHEN PENETRATION TESTING IS REQUIRED' metadata={'source': './data/General AppSec Related.pdf', 'page': 23}\n",
      "\n",
      "page_content='new feature or functionality meets the conditions in criterion 5 of Penetration Testing Criteria.\\nIf you are concerned about the scalability or sustainability of these security review criteria, please discuss\\nthem with your AWS security engineer or AWS security manager as we love working through these kinds of\\nproblems with our partner service teams.\\nAdditional Commentary\\nAny change, (e.g., a new internal or external service/feature/enhancement, a new  engagement with an' metadata={'source': './data/General AppSec Related.pdf', 'page': 1}\n",
      "\n",
      "page_content='classes.\\nUsing the baseline security control checklist, AWS security bar and the automated scanners (ACAT, MonkeyTester and SI) as\\nreferences, we review all the assets classes described in the different system models / threat models. With this exercise we\\nensure that all assets classes are reviewed against the AWS security baseline.\\n●\\n●\\n●\\n●\\n●● PT determination criteria \\nPenetration Testing Criteria\\nPrimary Owner aws-security (POSIX) \\nLast modified 2 months ago by afreenbh.\\n PT Scoping Template' metadata={'source': './data/General AppSec Related.pdf', 'page': 21}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is penetration testing in AWS Security?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66f3662e-14c7-4355-bc5f-d56063b1f61e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is AWS security?\n",
      "\n",
      "Result:  Based on the context provided, AWS security refers to the measures and controls implemented by Amazon Web Services (AWS) to protect its infrastructure, services, and customer data from various security threats. The context mentions several security-related concepts and tools, including:\n",
      "\n",
      "1. Baseline security control checklist: A reference guide for security controls that AWS uses to evaluate the security posture of its services.\n",
      "2. Automated scanners (ACAT, MonkeyTester, and SI): Tools used to automate security testing and vulnerability assessment of AWS services.\n",
      "3. AWS Security Bar: A security framework that provides a set of security controls and guidelines for AWS services to follow.\n",
      "4. Penetration testing: A security assessment methodology used to identify vulnerabilities in AWS services.\n",
      "5. Security canaries / tests: A process of analyzing mitigations with the service team to identify security improvements.\n",
      "\n",
      "Overall, AWS security is focused on ensuring the confidentiality, integrity, and availability of its services and customer data by implementing various security controls, tools, and processes.\n",
      "\n",
      "Context Documents: \n",
      "page_content='security controls using the following as a reference\\nBaseline security control\\n( https://w.amazon.com/bin/view/AWS_IT_Security/AppSec/ETSE/BaselineSecurityControls#HReleaseNotes )\\nAutomation scanners( ACAT, Monkey tester and SI)\\nAWS Security Bar ( https://w.amazon.com/bin/view/AWS_IT_Security/AWS_Security_Bar )\\nPerform a Pentest of the AWS service.\\nSecurity Canaries / Tests : Together with the service team, perform analysis on the mitigations to identity security' metadata={'source': './data/General AppSec Related.pdf', 'page': 15}\n",
      "\n",
      "page_content='SnowBall), or to support other AWS products (e.g., Firecracker CPLD, Nitro card, Blackfoot16)\\nChanges to security-relevant processes (such as customer service account ownership change procedures)\\nA security device or system with any type of network connectvity to other applications or systems\\nIntroduction of a service or device where the functionality could have impact on the availability, integrity, or confidentiality\\nof AWS infrastructure' metadata={'source': './data/General AppSec Related.pdf', 'page': 0}\n",
      "\n",
      "page_content='comprise an AWS service. We do this to gain assurances that these systems\\nmeet the AWS Security bar, and are operating in an environment in which we\\ncan continuously re-affirm the trustworthiness of our systems.\\nTenets( Unless you know better ones)\\n●\\n●\\n●\\n●\\n●Focus on delivering actionable feedback and value to the the service teams builder community\\nWe do not settle until an AWS service meets the customer security expectations and ensure that the holistic review\\nhelps raise the security bar.' metadata={'source': './data/General AppSec Related.pdf', 'page': 15}\n",
      "\n",
      "page_content='classes.\\nUsing the baseline security control checklist, AWS security bar and the automated scanners (ACAT, MonkeyTester and SI) as\\nreferences, we review all the assets classes described in the different system models / threat models. With this exercise we\\nensure that all assets classes are reviewed against the AWS security baseline.\\n●\\n●\\n●\\n●\\n●● PT determination criteria \\nPenetration Testing Criteria\\nPrimary Owner aws-security (POSIX) \\nLast modified 2 months ago by afreenbh.\\n PT Scoping Template' metadata={'source': './data/General AppSec Related.pdf', 'page': 21}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is AWS security?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b95406d-6476-40b4-bb9b-0157dfcb48bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When do I need an appsec review?\n",
      "\n",
      "Result:  Based on the provided context, you need an AppSec review any time you're making a change (or releasing a new system or service) that could impact the security of customers, AWS, or Amazon. Specifically, all launches (alpha, beta, gamma, demo, GA, public, or private) require a security review. Additionally, if you are updating or publishing documentation that includes code snippets, templates, or configuration details, the content should be reviewed by an AppSec engineer. You can create a security ticket for AppSec review through the following link: <https://appsec.corp.amazon.com>.\n",
      "\n",
      "Context Documents: \n",
      "page_content=\"General AppSec Related\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n●\\n○\\n○\\n●\\n●\\n●\\n●\\n●\\n● How do I know if I need a security review for this change? \\nWhen do I need an Appsec review?\\nA security review is required any time you're making a change (or releasing a new system or service) that could impact\\nthe security of customers, AWS, or Amazon. More specifically...\\nAll launches (alpha, beta, gamma, demo, GA, public, or private) require a security review.\" metadata={'source': './data/General AppSec Related.pdf', 'page': 0}\n",
      "\n",
      "page_content=\"below.\\nIf you are unsure, please complete the  Security Review Intake , and a security engineer will determine whether a review\\nis appropriate. You may also want to consider reaching out to the AppSec review engineer who is the affinity for your\\nservice team (using our  Office Hours ) and setup a quick meeting to get guidance on if a review is necessary or not.\\nSending an email or instant message to your engineer is also acceptable in case you're pressed for time or wish to get a\\nmore immediate response.\" metadata={'source': './data/General AppSec Related.pdf', 'page': 0}\n",
      "\n",
      "page_content='documents to account for the new feature changes.\\nContent Review\\nIn the event you are not be making any feature changes to your service, however, you are updating or\\npublishing documentation that includes code snippets, templates or configuration details, the content\\nshould be reviewed by an AppSec engineer. Cut us a consultation ticket so that we can review the content\\nas part of the  Content Review Process  and confirm that an AppSec review is not needed.' metadata={'source': './data/General AppSec Related.pdf', 'page': 1}\n",
      "\n",
      "page_content='as part of the  Content Review Process  and confirm that an AppSec review is not needed.\\n Where can I create a security ticket for AppSec Review? \\nRefer to this link:\\xa0 https://appsec.corp.amazon.com \\n Where can I cut a Talos ticket?' metadata={'source': './data/General AppSec Related.pdf', 'page': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"When do I need an appsec review?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cafc76f2-fe44-478a-81e7-24201905a104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the BSC Structure?\n",
      "\n",
      "Result:  Based on the provided context, the BSC Structure is as follows:\n",
      "\n",
      "1. Applicability: The BSCs are applicable where a customer has a strong expectation of the control. The control must be related to a security control and not merely a process hook.\n",
      "2. Scope: The scope of the control is sufficiently abstract while remaining specific to a topic. The control is not too broad, such as \"Limit actions to the minimum necessary,\" but rather specific, such as \"Encrypt all data at rest using automatically rotated KMS keys.\"\n",
      "3. Preview, GA, etc.): The BSCs are intended to give teams a reasonable, transparent baseline from which to start. They help teams reason about specific controls and enable them to build security into products from the start.\n",
      "4. Leadership Team Roles and Responsibilities: The BSC Leadership Team is responsible for reviewing and approving proposed BSC adds/changes/deletes, guiding, mentoring, and providing feedback on BSC adds/changes/delete requests, maintaining authoritative package repos, and continuously calibrating with other forums/initiatives to be proactive in adopting BSCs for tomorrow's problems.\n",
      "\n",
      "Therefore, the BSC Structure consists of the following components:\n",
      "\n",
      "1. Applicability: The control is applicable where a customer has a strong expectation of the control.\n",
      "2. Scope: The control is sufficiently abstract while remaining specific to a topic.\n",
      "3. Preview, GA, etc.: The BSCs are intended to give teams a reasonable, transparent baseline from which to start.\n",
      "4. Leadership Team Roles and Responsibilities: The BSC Leadership Team is responsible for reviewing and approving proposed BSCs, guiding teams, and maintaining authoritative package repos.\n",
      "\n",
      "Context Documents: \n",
      "page_content='granular, but it should be clear to builders when the intent of the BSC is satisfied.\\ne.g., “encrypt all data at rest using automatically rotated KMS keys” is not S3 or DDB specific, but is still clear and\\nactionable.\\nScope: Is the scope of the control sufficiently abstract while remaining specific to a topic?\\nToo broad: “Limit actions to the minimum necessary” - network rules? instance roles? IAM policies?' metadata={'source': './data/General AppSec Related.pdf', 'page': 3}\n",
      "\n",
      "page_content='preview, GA, etc.).\\nThe BSCs are intended to give teams a reasonable, transparent baseline from which to start. They help teams reason\\nabout specific controls, and enable them to build security into products from the start. All teams need to have strong\\nsecurity, and BSCs help by reducing the cognitive load around fundamental controls so that we can spend more time\\ntalking about product-specific security properties and decisions. BSCs are not policies. They’re here to help calibrate' metadata={'source': './data/General AppSec Related.pdf', 'page': 2}\n",
      "\n",
      "page_content='will review the proposal against the criteria below.\\nApplicability: Where a candidate BSC would be applicable, does or will a customer have a strong expectation of the\\ncontrol? Should it be required? BSCs must be related to a security control and not merely a process hook.\\ne.g., “Allow customers to provide their own customer owned KMS key that your service will use for encrypting their\\ncontent.”\\nExamples that usually will not become BSCs:\\nRequirements to engage a specific team' metadata={'source': './data/General AppSec Related.pdf', 'page': 3}\n",
      "\n",
      "page_content='and implement changes.\\nBSC Leadership Team Roles and Responsibilities\\nKeeper of the BSCs\\nReview and approve proposed BSC adds/changes/deletes\\nGuide, mentor and provide feedback on BSC adds/changes/delete requests\\nMaintain authoritative package repos\\nContinuously calibrate with other forums/initiatives to be proactive in adopting BSCs for tomorrow’s problems\\nRegular syncs with other teams, e.g. security automation teams like ASAT' metadata={'source': './data/General AppSec Related.pdf', 'page': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the BSC Structure?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94fbfc-6946-4a84-a0ca-bd65222cc5a8",
   "metadata": {},
   "source": [
    "## CLEAN UP YOUR ENDPOINT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a984025-312b-4d56-b3d4-997a448cd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "# sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n",
    "# sagemaker_client.delete_endpoint(EndpointName=llm_model_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
