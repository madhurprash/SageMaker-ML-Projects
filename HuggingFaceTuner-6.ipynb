{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27100626-4aa0-455a-bb3b-69f30555c3e3",
   "metadata": {},
   "source": [
    "# Meeting Notes Summarizer: AWS Summarize\n",
    "\n",
    "### This code represents using SageMaker, and HuggingFace, to summarize the transcripts from a given meeting, and organizing them for further reference.\n",
    "\n",
    "## GOALS:\n",
    "\n",
    "#### Integrate one of the HuggingFace pretrained models, that we will fine tune based on a lot of self created data, and then build and deploy. \n",
    "\n",
    "#### STEPS:\n",
    "\n",
    "1. Build, train and deploy the model from the HuggingFace pretrained model library.\n",
    "\n",
    "2. Leverage self recordings from Chime, with all of the transcripts stored in the s3 bucket that we will use for reference and training.\n",
    "\n",
    "3. Use the trained model to create an efficient notes organizer for AWS employees and meeting members.\n",
    "\n",
    "#### Integrate a Speech to text converter to convert speech and points from different speakers in the meeting in a live document for our model to refer to and train our data on.\n",
    "\n",
    "## STEP 0: INSTALL THE TRANSFORMERS SDK LOCALLY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876e9d42-254c-47ce-9303-707e6c1cafd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "transformers == 4.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8718bfb-dadb-4bf4-90db-5985233a4660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.6.1\n",
      "  Using cached transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (2.28.2)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (4.64.1)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (8.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Installing collected packages: tokenizers, regex, filelock, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 huggingface-hub-0.0.8 regex-2023.6.3 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Represents installing the requirements for this model\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd4c89-6aea-49a5-85d7-407d75a0cd5b",
   "metadata": {},
   "source": [
    "## STEP 1: DOWNLOAD A PRETRAINED FACEBOOK BART MODEL AND TEST IT LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6008eda5-c8e0-4de0-9eda-dcabe2eb0033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "notes_gpt = \"knkarthick/MEETING_SUMMARY\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(notes_gpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(notes_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fc47e36-def2-49db-b42e-f3ea706307e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:2120: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: Karen's parents forced her to bear the name Karen. After her parents passed away, Kathy decided to change her name to Kathy. She noticed a couple arguing at the Social Security Administration about what their married last name ought to be....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "## Represents displaying the output in the way we need\n",
    "def get_outputs(sample_outputs, tokenizer):\n",
    "    \n",
    "    ## Represents taking in a tokenizer, and raw output from the given model, decoding and \n",
    "    ## formatting the output nicely\n",
    "    rt = []\n",
    "    \n",
    "    print(\"Output:\\n\" + 100 * '-')\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        txt = tokenizer.decode(sample_output, skip_special_tokens = True)\n",
    "        print(\"{}: {}...\".format(i, txt))\n",
    "        print('')\n",
    "        rt.append(txt)\n",
    "        \n",
    "    return rt\n",
    "\n",
    "## Setting the seed helps us ensure reproducibility, and when the seed is consistent, the model outputs will be consistent\n",
    "set_seed(42)\n",
    "\n",
    "text = \"Karen hadn’t asked to be named Karen. She hadn’t asked to be dressed in modest dresses, always with tights and shoes. She certainly hadn’t asked for her parents to use the sort of psychological conditioning that led to so many people saying, “Butt out, Karen!” Once Mom and Dad passed away, Karen decided she’d finally do something about all the negative comments. She colored her hair, bought a pair of honest-to-goodness jeans, and changed her name to Kathy. Upon leaving the Social Security Administration, she spied a couple arguing heatedly about what their married last name ought to be. Kathy couldn’t stand to see and hear such animosity between two people in love, and walked toward them. Before she could even open her mouth, however, the woman turned to her and said, “Butt out, Karen!”.\"\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors = 'pt')\n",
    "\n",
    "sample_outputs = model.generate(input_ids, \n",
    "                                     do_sample = True, \n",
    "                                     ##max_length = 90,\n",
    "                                     num_return_sequences = 1)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a2ee5-073c-44e0-867b-77436e79116b",
   "metadata": {},
   "source": [
    "## STEP 2: FINE TUNE THE FACEBOOK BART SUMMARIZER WITH A REAL MEETING TRANSCRIPT (SELF-RECORDED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83354f07-09bb-4597-adfd-d8d251744640",
   "metadata": {},
   "source": [
    "#### Here, we will tune the model on a real experiment done where I used myself to generate a meeting transcript, to check how the model performs on the transcript:\n",
    "\n",
    "#### GOALS:\n",
    "\n",
    "1. Summarizing a transcript in an organized way\n",
    "\n",
    "2. Making sure all important points have been come across to the reader (maybe we assign labels to the meeting)\n",
    "\n",
    "3. Make sure the model uses the label to pick up the important pointers from the meeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec0a7eb-0ca0-47ba-a8d9-3ae436f1ca30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.txt\n",
    "\n",
    "Madhur: Hey, how's it going? So let me turn on the transcript uh language preference. Let's go with English for now. OK. \n",
    "So I can see that the machine generated captions are by Amazon transcribe. Well, this is the first time I'm joining \n",
    "Amazon Shine with my hair all open. Usually during my workout, I tie, tie them back because it just looks uh I look like a broccoli. \n",
    "But anyways, uh this is an experiment. So I'm trying to uh this, I'm trying to work on a project where for every meeting, I'm trying to \n",
    "extract the transcripts through the chime calls and then display it after the calls have ended or the meetings have ended to the uh \n",
    "members of the meeting in a summarized manner or in a manner where they feel comfortable to read. Maybe they feel like being more organized \n",
    "after they missed a huge meeting. So they just want to look at the, the important pointers. So I will be focusing on taking this transcript and \n",
    "actually using it in the prototype that I'm trying to create. And let's see how it goes. I'm trying to see if I can get this transcript really long \n",
    "so that I can see that my protype works or not. And I'm just looking at the transcripts right now because I'm just kind of distracted at how Amazon\n",
    "chime also has a one second delay, maybe a millisecond delay in their um meeting. So I can see my lips moving a bit slower than they actually are. \n",
    "So, so, yeah, a lot of redundant information there. Let's move on forward and uh, try this transcript out. All right. See you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5048d1-c92c-49e8-b108-c0ad7798317d",
   "metadata": {},
   "source": [
    "#### We are going to use a script written by hunning face: run CLM that sits on the Hugging Face repo and we can pass in generic text (we do not have to tokenize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e928c5-556a-4888-9bd5-0c841d3732cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "## Represents going over the training transcript sample above\n",
    "\n",
    "with open('train.txt') as f:\n",
    "    for row in f.readlines():\n",
    "        d = row.strip()\n",
    "        if len(d) > 0:\n",
    "            data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e660cf-d639-4ad2-97c1-0046ffe2d7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Madhur: Hey, how's it going? So let me turn on the transcript uh language preference. Let's go with English for now. OK.\", \"So I can see that the machine generated captions are by Amazon transcribe. Well, this is the first time I'm joining\", 'Amazon Shine with my hair all open. Usually during my workout, I tie, tie them back because it just looks uh I look like a broccoli.', \"But anyways, uh this is an experiment. So I'm trying to uh this, I'm trying to work on a project where for every meeting, I'm trying to\", 'extract the transcripts through the chime calls and then display it after the calls have ended or the meetings have ended to the uh', 'members of the meeting in a summarized manner or in a manner where they feel comfortable to read. Maybe they feel like being more organized', 'after they missed a huge meeting. So they just want to look at the, the important pointers. So I will be focusing on taking this transcript and', \"actually using it in the prototype that I'm trying to create. And let's see how it goes. I'm trying to see if I can get this transcript really long\", \"so that I can see that my protype works or not. And I'm just looking at the transcripts right now because I'm just kind of distracted at how Amazon\", 'chime also has a one second delay, maybe a millisecond delay in their um meeting. So I can see my lips moving a bit slower than they actually are.']\n"
     ]
    }
   ],
   "source": [
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075144e7-c409-4a74-8635-93f726be7f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train.txt to s3://sagemaker-us-east-1-988564344122/bart/train.txt\n"
     ]
    }
   ],
   "source": [
    "## Represents importing the sagemaker role\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "train_file_name = 'train.txt'\n",
    "s3_train_data = 's3://{}/bart/{}'.format(bucket, train_file_name)\n",
    "\n",
    "!aws s3 cp {train_file_name} {s3_train_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b774a2d-8133-49b6-afaf-e75fa87d625b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.132.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.175.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.13.0)\n",
      "Collecting platformdirs\n",
      "  Using cached platformdirs-3.10.0-py3-none-any.whl (17 kB)\n",
      "Collecting attrs<24,>=23.1.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting boto3<2.0,>=1.26.131\n",
      "  Using cached boto3-1.28.20-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Collecting PyYAML~=6.0\n",
      "  Using cached PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.18.6-py3-none-any.whl (83 kB)\n",
      "Collecting tblib==1.7.0\n",
      "  Using cached tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Collecting botocore<1.32.0,>=1.31.20\n",
      "  Using cached botocore-1.31.20-py3-none-any.whl (11.1 MB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Using cached pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.10.2)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2022.7.1)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.20->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n",
      "Installing collected packages: tblib, rpds-py, PyYAML, platformdirs, pkgutil-resolve-name, attrs, referencing, botocore, jsonschema-specifications, jsonschema, boto3, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.70\n",
      "    Uninstalling botocore-1.29.70:\n",
      "      Successfully uninstalled botocore-1.29.70\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.70\n",
      "    Uninstalling boto3-1.26.70:\n",
      "      Successfully uninstalled boto3-1.26.70\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.132.0\n",
      "    Uninstalling sagemaker-2.132.0:\n",
      "      Successfully uninstalled sagemaker-2.132.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.70 requires botocore==1.29.70, but you have botocore 1.31.20 which is incompatible.\n",
      "awscli 1.27.70 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 attrs-23.1.0 boto3-1.28.20 botocore-1.31.20 jsonschema-4.18.6 jsonschema-specifications-2023.7.1 pkgutil-resolve-name-1.3.10 platformdirs-3.10.0 referencing-0.30.2 rpds-py-0.9.2 sagemaker-2.175.0 tblib-1.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.175.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.28.20)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.18.6)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.10.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.20 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.20)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.10.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.9.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2022.7.1)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.20->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker\n",
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c32f1a-20d0-4631-adf1-ba24e6350441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2023-08-06-00-18-54-732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-06 00:19:14 Starting - Starting the training job...\n",
      "2023-08-06 00:19:40 Starting - Preparing the instances for training.........\n",
      "2023-08-06 00:21:11 Downloading - Downloading input data\n",
      "2023-08-06 00:21:11 Training - Downloading the training image.....................\n",
      "2023-08-06 00:24:37 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-08-06 00:24:56,950 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-08-06 00:24:56,969 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-06 00:24:56,981 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:24:56,984 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:24:57,223 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=0.12.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (0.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.13.1+cu117)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.1.97)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting evaluate\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.4/81.4 kB 3.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (5.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.3->-r requirements.txt (line 2)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.28.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (11.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2023.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2022.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: evaluate\u001b[0m\n",
      "\u001b[34mSuccessfully installed evaluate-0.4.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.2.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:00,773 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:00,773 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:00,816 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:00,851 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:00,884 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:00,898 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"do_train\": true,\n",
      "        \"model_name_or_path\": \"knkarthick/MEETING_SUMMARY\",\n",
      "        \"num_train_epochs\": 5,\n",
      "        \"output_dir\": \"/opt/ml/model\",\n",
      "        \"per_device_train_batch_size\": 64,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/train.txt\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-08-06-00-18-54-732\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-988564344122/huggingface-pytorch-training-2023-08-06-00-18-54-732/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_clm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_clm.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"do_train\":true,\"model_name_or_path\":\"knkarthick/MEETING_SUMMARY\",\"num_train_epochs\":5,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":64,\"train_file\":\"/opt/ml/input/data/train/train.txt\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_clm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_clm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-988564344122/huggingface-pytorch-training-2023-08-06-00-18-54-732/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"do_train\":true,\"model_name_or_path\":\"knkarthick/MEETING_SUMMARY\",\"num_train_epochs\":5,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":64,\"train_file\":\"/opt/ml/input/data/train/train.txt\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2023-08-06-00-18-54-732\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-988564344122/huggingface-pytorch-training-2023-08-06-00-18-54-732/source/sourcedir.tar.gz\",\"module_name\":\"run_clm\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_clm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--do_train\",\"True\",\"--model_name_or_path\",\"knkarthick/MEETING_SUMMARY\",\"--num_train_epochs\",\"5\",\"--output_dir\",\"/opt/ml/model\",\"--per_device_train_batch_size\",\"64\",\"--train_file\",\"/opt/ml/input/data/train/train.txt\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DO_TRAIN=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=knkarthick/MEETING_SUMMARY\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=/opt/ml/input/data/train/train.txt\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 run_clm.py --do_train True --model_name_or_path knkarthick/MEETING_SUMMARY --num_train_epochs 5 --output_dir /opt/ml/model --per_device_train_batch_size 64 --train_file /opt/ml/input/data/train/train.txt\u001b[0m\n",
      "\u001b[34m[2023-08-06 00:25:03.063: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:03,070 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:03,102 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdo_eval=False,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=no,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=1,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=None,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=5e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=False,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=passive,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/runs/Aug06_00-25-06_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=linear,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=None,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=5.0,\u001b[0m\n",
      "\u001b[34moptim=adamw_hf,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=64,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=steps,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - WARNING - datasets.builder - Using custom data configuration default-296ee27d544adc46\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset Infos from /opt/conda/lib/python3.9/site-packages/datasets/packaged_modules/text\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 1/1 [00:00<00:00, 5629.94it/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.download.download_manager - Downloading took 0.0 min\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 1/1 [00:00<00:00, 958.48it/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.utils.info_utils - Unable to verify checksums.\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.builder - Generating train split\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\u001b[0m\n",
      "\u001b[34mDataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 857.03it/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - WARNING - datasets.builder - Using custom data configuration default-296ee27d544adc46\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset Infos from /opt/conda/lib/python3.9/site-packages/datasets/packaged_modules/text\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.builder - Overwrite dataset info from restored data version.\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - WARNING - datasets.builder - Found cached dataset text (/root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - WARNING - datasets.builder - Using custom data configuration default-296ee27d544adc46\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset Infos from /opt/conda/lib/python3.9/site-packages/datasets/packaged_modules/text\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.builder - Overwrite dataset info from restored data version.\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - WARNING - datasets.builder - Found cached dataset text (/root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:06 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 1.59k/1.59k [00:00<00:00, 217kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-08-06 00:25:07,132 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-08-06 00:25:07,132 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-08-06 00:25:07,133 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"knkarthick/MEETING_SUMMARY\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {},\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-08-06 00:25:07,133 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"knkarthick/MEETING_SUMMARY\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {},\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json: 100%|██████████| 337/337 [00:00<00:00, 120kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 51.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 37.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 31.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 76.5kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/vocab.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/vocab.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/merges.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/merges.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,979 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,979 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,978 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,979 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-08-06 00:25:07,979 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.63G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 41.9M/1.63G [00:00<00:04, 368MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 83.9M/1.63G [00:00<00:04, 376MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 126M/1.63G [00:00<00:04, 356MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 168M/1.63G [00:00<00:04, 350MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 210M/1.63G [00:00<00:04, 347MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 252M/1.63G [00:00<00:03, 351MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 294M/1.63G [00:00<00:03, 351MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 336M/1.63G [00:00<00:03, 348MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 377M/1.63G [00:01<00:03, 350MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 419M/1.63G [00:01<00:03, 363MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 461M/1.63G [00:01<00:03, 377MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 503M/1.63G [00:01<00:02, 386MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▎      | 545M/1.63G [00:01<00:02, 392MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 587M/1.63G [00:01<00:02, 399MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▊      | 629M/1.63G [00:01<00:02, 403MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████▏     | 671M/1.63G [00:01<00:02, 405MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 713M/1.63G [00:01<00:02, 406MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▋     | 755M/1.63G [00:01<00:02, 406MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 797M/1.63G [00:02<00:02, 409MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 839M/1.63G [00:02<00:01, 411MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 881M/1.63G [00:02<00:01, 408MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 923M/1.63G [00:02<00:01, 407MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 965M/1.63G [00:02<00:01, 405MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 1.01G/1.63G [00:02<00:01, 405MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 1.05G/1.63G [00:02<00:01, 397MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 1.09G/1.63G [00:02<00:01, 403MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 1.13G/1.63G [00:02<00:01, 400MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 1.17G/1.63G [00:03<00:01, 356MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 1.22G/1.63G [00:03<00:01, 371MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 1.26G/1.63G [00:03<00:00, 380MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 1.30G/1.63G [00:03<00:00, 380MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 1.34G/1.63G [00:03<00:00, 377MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 1.38G/1.63G [00:03<00:00, 379MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 1.43G/1.63G [00:03<00:00, 382MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 1.47G/1.63G [00:03<00:00, 384MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 1.51G/1.63G [00:03<00:00, 386MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 1.55G/1.63G [00:04<00:00, 374MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 1.59G/1.63G [00:04<00:00, 379MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.63G/1.63G [00:04<00:00, 382MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2275] 2023-08-06 00:25:12,438 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2275] 2023-08-06 00:25:12,438 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--knkarthick--MEETING_SUMMARY/snapshots/e34cab124a21fabf9a4eede2ab869dd24b93dd7b/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:543] 2023-08-06 00:25:13,464 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.0\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:543] 2023-08-06 00:25:13,464 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 62,\n",
      "  \"min_length\": 11,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.0\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:2847] 2023-08-06 00:25:16,558 >> Some weights of the model checkpoint at knkarthick/MEETING_SUMMARY were not used when initializing BartForCausalLM: ['model.encoder.layers.8.fc1.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'final_logits_bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.shared.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BartForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BartForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2865] 2023-08-06 00:25:16,558 >> All the weights of BartForCausalLM were initialized from the model checkpoint at knkarthick/MEETING_SUMMARY.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use BartForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:2847] 2023-08-06 00:25:16,558 >> Some weights of the model checkpoint at knkarthick/MEETING_SUMMARY were not used when initializing BartForCausalLM: ['model.encoder.layers.8.fc1.weight', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.4.fc2.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.encoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.1.fc1.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.encoder.layers.1.fc2.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.0.fc2.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.9.fc1.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.10.fc2.bias', 'model.encoder.layernorm_embedding.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.weight', 'model.encoder.layers.2.fc2.weight', 'model.encoder.layers.7.fc1.bias', 'model.encoder.layers.5.fc2.bias', 'model.encoder.layers.0.self_attn.q_proj.weight', 'model.encoder.layers.7.fc2.weight', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.weight', 'final_logits_bias', 'model.encoder.layers.0.self_attn_layer_norm.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.0.fc2.weight', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.0.fc1.weight', 'model.encoder.layers.0.fc1.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.4.fc1.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.10.fc1.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.6.fc2.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.4.fc2.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.0.self_attn.k_proj.weight', 'model.encoder.layers.0.self_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.2.fc1.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.11.fc2.weight', 'model.encoder.layers.6.fc2.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.encoder.layers.1.final_layer_norm.weight', 'model.encoder.layers.10.fc2.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.8.fc1.bias', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.8.final_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.encoder.layers.11.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.final_layer_norm.bias', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.7.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.9.final_layer_norm.bias', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.9.fc1.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.shared.weight', 'model.encoder.layernorm_embedding.weight', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.0.final_layer_norm.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.encoder.embed_tokens.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.1.fc1.bias', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.11.fc1.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.encoder.layers.6.fc1.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.weight', 'model.encoder.layers.0.final_layer_norm.weight', 'model.encoder.embed_positions.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.9.fc2.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.encoder.layers.8.fc2.bias', 'model.encoder.layers.7.fc2.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.3.final_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BartForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BartForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2865] 2023-08-06 00:25:16,558 >> All the weights of BartForCausalLM were initialized from the model checkpoint at knkarthick/MEETING_SUMMARY.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use BartForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2522] 2023-08-06 00:25:16,632 >> Generation config file not found, using a generation config created from the model config.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2522] 2023-08-06 00:25:16,632 >> Generation config file not found, using a generation config created from the model config.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-109a0bf8e79f9ba0.arrow\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 200.88ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-6994e36458bafc96.arrow\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00, 514.13ba/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-ff224449cdc1cf0e.arrow\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|██████████| 1/1 [00:00<00:00, 342.56ba/s]\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34m08/06/2023 00:25:17 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-296ee27d544adc46/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e7cf5620802d276b.arrow\u001b[0m\n",
      "\u001b[34mGrouping texts in chunks of 1024: 100%|██████████| 1/1 [00:00<00:00, 427.25ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1650] 2023-08-06 00:25:18,962 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1650] 2023-08-06 00:25:18,962 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1651] 2023-08-06 00:25:18,962 >>   Num examples = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1652] 2023-08-06 00:25:18,962 >>   Num Epochs = 5\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1653] 2023-08-06 00:25:18,963 >>   Instantaneous batch size per device = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1651] 2023-08-06 00:25:18,962 >>   Num examples = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1652] 2023-08-06 00:25:18,962 >>   Num Epochs = 5\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1653] 2023-08-06 00:25:18,963 >>   Instantaneous batch size per device = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1654] 2023-08-06 00:25:18,963 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1654] 2023-08-06 00:25:18,963 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1655] 2023-08-06 00:25:18,963 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1656] 2023-08-06 00:25:18,963 >>   Total optimization steps = 5\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1655] 2023-08-06 00:25:18,963 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1656] 2023-08-06 00:25:18,963 >>   Total optimization steps = 5\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1657] 2023-08-06 00:25:18,964 >>   Number of trainable parameters = 254084096\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1657] 2023-08-06 00:25:18,964 >>   Number of trainable parameters = 254084096\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-08-06 00:25:19.076: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[2023-08-06 00:25:19.116 algo-1:55 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-08-06 00:25:19.156 algo-1:55 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m20%|██        | 1/5 [00:01<00:05,  1.25s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:01<00:00,  2.56it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:01<00:00,  4.27it/s]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1901] 2023-08-06 00:25:20,569 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1901] 2023-08-06 00:25:20,569 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m{'train_runtime': 1.6076, 'train_samples_per_second': 3.11, 'train_steps_per_second': 3.11, 'train_loss': 12.606515502929687, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:01<00:00,  4.27it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:01<00:00,  3.11it/s]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-08-06 00:25:20,572 >> Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-08-06 00:25:20,572 >> Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-08-06 00:25:20,574 >> Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-08-06 00:25:20,574 >> Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:336] 2023-08-06 00:25:20,575 >> Configuration saved in /opt/ml/model/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:336] 2023-08-06 00:25:20,575 >> Configuration saved in /opt/ml/model/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-08-06 00:25:21,967 >> Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-08-06 00:25:21,967 >> Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2160] 2023-08-06 00:25:21,967 >> tokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2160] 2023-08-06 00:25:21,967 >> tokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2167] 2023-08-06 00:25:21,968 >> Special tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2167] 2023-08-06 00:25:21,968 >> Special tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m***** train metrics *****\n",
      "  epoch                    =        5.0\u001b[0m\n",
      "\u001b[34mtrain_loss               =    12.6065\n",
      "  train_runtime            = 0:00:01.60\n",
      "  train_samples            =          1\n",
      "  train_samples_per_second =       3.11\n",
      "  train_steps_per_second   =       3.11\u001b[0m\n",
      "\u001b[34m[INFO|modelcard.py:449] 2023-08-06 00:25:22,230 >> Dropping the following result as it does not have all the necessary fields:\u001b[0m\n",
      "\u001b[34m{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\u001b[0m\n",
      "\u001b[34m[INFO|modelcard.py:449] 2023-08-06 00:25:22,230 >> Dropping the following result as it does not have all the necessary fields:\u001b[0m\n",
      "\u001b[34m{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:22,831 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:22,832 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-06 00:25:22,832 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-08-06 00:25:38 Uploading - Uploading generated training model\n",
      "2023-08-06 00:26:49 Completed - Training job completed\n",
      "Training seconds: 362\n",
      "Billable seconds: 362\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\t\t\n",
    "hyperparameters = {\n",
    "\t'model_name_or_path':'knkarthick/MEETING_SUMMARY',\n",
    "\t'output_dir':'/opt/ml/model',\n",
    "    'do_train':True,\n",
    "    'train_file': '/opt/ml/input/data/train/{}'.format(train_file_name),\n",
    "    'num_train_epochs': 5, \n",
    "    \"per_device_train_batch_size\": 64,\n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.26.0/examples/pytorch/seq2seq\n",
    "}\n",
    "\n",
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.26.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "\tentry_point='run_clm.py',\n",
    "\tsource_dir='examples/pytorch/language-modeling',\n",
    "\tinstance_type='ml.p3.2xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.26.0',\n",
    "\tpytorch_version='1.13.1',\n",
    "\tpy_version='py39',\n",
    "\thyperparameters = hyperparameters,\n",
    "    ## Pass the training compiler config to speed up your job\n",
    "    ##compiler_config = TrainingCompilerConfig(), \n",
    "    environment = {'GPU_NUM_DEVICES': '1'},\n",
    "    disable_profiler = True, \n",
    "    debugger_hook_config = False\n",
    ")\n",
    "\n",
    "# starting the train job\n",
    "huggingface_estimator.fit({'train': s3_train_data}, wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2b2a6-50f2-456b-a3a8-40cce00f92d3",
   "metadata": {},
   "source": [
    "## STEP 4: TESTING OUR TRAINED MODEL LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356ec3ff-9103-4980-a840-72634647da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "import time\n",
    "\n",
    "try:\n",
    "    s3_model_data = huggingface_estimator.model_data\n",
    "    local_model_path = 'bart_finetuned'\n",
    "    \n",
    "except:\n",
    "    time.sleep(5)\n",
    "    s3_model_data = huggingface_estimator.model_data\n",
    "    local_model_path = 'bart_finetuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244f505f-b5c9-4896-ad7b-b85a39776f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘bart_finetuned’: File exists\n",
      "download: s3://sagemaker-us-east-1-988564344122/huggingface-pytorch-training-2023-08-06-00-18-54-732/output/model.tar.gz to bart_finetuned/model.tar.gz\n",
      "generation_config.json\n",
      "tokenizer.json\n",
      "merges.txt\n",
      "tokenizer_config.json\n",
      "pytorch_model.bin\n",
      "all_results.json\n",
      "trainer_state.json\n",
      "special_tokens_map.json\n",
      "training_args.bin\n",
      "vocab.json\n",
      "config.json\n",
      "train_results.json\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "!mkdir {local_model_path}\n",
    "!aws s3 cp {s3_model_data} {local_model_path}\n",
    "!tar -xvf {local_model_path}/model.tar.gz -C {local_model_path}\n",
    "!rm {local_model_path}/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95821af5-ae73-4003-b85a-d137da553d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load into the transformer SDK framework\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"knkarthick/MEETING_SUMMARY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7776197c-2fa8-42c1-ab4f-c02e8bc23d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to make sure we cna run inference with this model locally\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8766bc3-651a-4ec3-987d-5d097816695c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation_utils.py:2120: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: Madhur is working on a project where he wants to extract the transcripts from the Amazon Chime calls and present them to the participants in a summarized manner or in a manner where they feel comfortable to read them....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "## Setting the seed helps us ensure reproducibility, and when the seed is consistent, the model outputs will be consistent\n",
    "set_seed(42)\n",
    "\n",
    "text = 'Madhur: Hey, hows it going? So let me turn on the transcript uh language preference. Lets go with English for now. OK. So I can see that the machine generated captions are by Amazon transcribe. Well, this is the first time Im joining  Amazon Shine with my hair all open. Usually during my workout, I tie, tie them back because it just looks uh I look like a broccoli.  But anyways, uh this is an experiment. So Im trying to uh this, Im trying to work on a project where for every meeting, Im trying to extract the transcripts through the chime calls and then display it after the calls have ended or the meetings have ended to the uh members of the meeting in a summarized manner or in a manner where they feel comfortable to read. Maybe they feel like being more organized after they missed a huge meeting. So they just want to look at the, the important pointers. So I will be focusing on taking this transcript and actually using it in the prototype that Im trying to create. And lets see how it goes. Im trying to see if I can get this transcript really long so that I can see that my protype works or not. And Im just looking at the transcripts right now because Im just kind of distracted at how Amazonchime also has a one second delay, maybe a millisecond delay in their um meeting. So I can see my lips moving a bit slower than they actually are. So, so, yeah, a lot of redundant information there. Lets move on forward and uh, try this transcript out. All right. See you.'\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors = 'pt')\n",
    "\n",
    "sample_outputs = model.generate(input_ids, \n",
    "                                     do_sample = True, \n",
    "                                     max_length = 90,\n",
    "                                     num_return_sequences = 1)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead8e0b-2bed-4682-a4b6-3c15d3f108b4",
   "metadata": {},
   "source": [
    "### Passing in different parameters to play with the sample outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6702dc31-0f2f-4095-837f-aac1fca3cb34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: Madhur is working on a project to extract the transcripts from the Amazon Chime calls and display them after the calls have ended. He is trying to create a prototype of the project....\n",
      "\n",
      "1: Madhur is working on a project to extract the transcripts from the Amazon Chime calls and present them to the participants in a summarized manner after the calls have ended....\n",
      "\n",
      "2: Madhur is working on a project to extract the transcripts from the Amazon Chime calls and present them to the participants in a summarized manner after the calls have ended. He is trying to create a prototype of the project....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_outputs = model.generate(input_ids, \n",
    "                                     do_sample = True, \n",
    "                                ## only pick tokens at and above this probability level\n",
    "                                top_p = 0.85,\n",
    "                                ## only pick from this many tokens\n",
    "                                top_k=200,\n",
    "                                     ##max_length = 90,\n",
    "                                     num_return_sequences = 3)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c163b7c3-a89c-4988-b1da-d5a0f0a10f78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: Madhur is working on a project to extract the transcripts from the Amazon Chime calls and display them after the calls have ended to give them to the participants of the meeting in a summarized manner or in a manner where they feel comfortable to read....\n",
      "\n",
      "1: Madhur is working on a project where he wants to extract the transcripts from the Amazon Chime calls and present them to the participants in a summarized manner or in a manner where they feel comfortable to read them....\n",
      "\n",
      "2: Madhur is working on a project to extract the transcripts from the Amazon Chime calls and display them after the calls have ended. He is trying to create a prototype of the project....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_outputs = model.generate(input_ids, \n",
    "                                     do_sample = True, \n",
    "                                ## only pick tokens at and above this probability level\n",
    "                                top_p = 0.95,\n",
    "                                ## only pick from this many tokens\n",
    "                                top_k=100,\n",
    "                                     ##max_length = 90,\n",
    "                                     num_return_sequences = 3)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4a93b-8dad-47bb-a24f-4116ecb5bf2d",
   "metadata": {},
   "source": [
    "### DEPLOYING OUR MODEL TO AN ENDPOINT BY PUBLISHING TO HUGGING FACE AND THEN DEPLOYING IT TO STREAMLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc22d55-a0ad-48fa-a0af-a263bf243b93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-training-2023-08-06-00-28-51-706\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-training-2023-08-06-00-28-51-706\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-training-2023-08-06-00-28-51-706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_endpoint = huggingface_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a69e6c2-cce4-491d-b77a-126f7cb38022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-training-2023-08-06-00-28-51-706'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_endpoint.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282578c1-387f-4d53-852d-2a581d1c18e2",
   "metadata": {},
   "source": [
    "# Meeting Notes Summarizer: AWS Instructor\n",
    "\n",
    "### This code represents using SageMaker, and HuggingFace, to use the text to develop some instructions based on the input given to the model\n",
    "\n",
    "## GOALS:\n",
    "\n",
    "#### Integrate one of the HuggingFace pretrained models, that we will fine tune based on a lot of self created data, and then build and deploy. \n",
    "\n",
    "#### STEPS:\n",
    "\n",
    "1. Build, train and deploy the model from the HuggingFace pretrained model library.\n",
    "\n",
    "2. Leverage self recordings from Chime, with all of the transcripts stored in the s3 bucket that we will use for reference and training.\n",
    "\n",
    "3. Use the trained model to create an efficient notes organizer for AWS employees and meeting members.\n",
    "\n",
    "#### Integrate a Speech to text converter to convert speech and points from different speakers in the meeting in a live document for our model to refer to and train our data on.\n",
    "\n",
    "## STEP 0: INSTALL THE TRANSFORMERS SDK LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "835b1f0f-4520-45c5-86b3-2f0b9ef304a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements1.txt\n",
    "\n",
    "transformers == 4.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "132d43d3-c9ae-4abb-b194-4bd98db4d9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.6.1\n",
      "  Using cached transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (4.64.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (2023.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements1.txt (line 2)) (3.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements1.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements1.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements1.txt (line 2)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements1.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements1.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements1.txt (line 2)) (8.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements1.txt (line 2)) (1.16.0)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.16.4\n",
      "    Uninstalling huggingface-hub-0.16.4:\n",
      "      Successfully uninstalled huggingface-hub-0.16.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.0.dev0\n",
      "    Uninstalling transformers-4.27.0.dev0:\n",
      "      Successfully uninstalled transformers-4.27.0.dev0\n",
      "Successfully installed huggingface-hub-0.0.8 tokenizers-0.10.3 transformers-4.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Represents installing the requirements for this model\n",
    "!pip install -r requirements1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6769b97-435a-4fa0-822d-23c2146430f4",
   "metadata": {},
   "source": [
    "## STEP 1: DOWNLOAD A PRETRAINED FACEBOOK BART MODEL AND TEST IT LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d70d95-4111-4ab4-b7f9-a48f1e072f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/zphang/transformers@llama_push\n",
      "  Cloning https://github.com/zphang/transformers (to revision llama_push) to /tmp/pip-req-build-6h9jekei\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/zphang/transformers /tmp/pip-req-build-6h9jekei\n",
      "  Running command git checkout -b llama_push --track origin/llama_push\n",
      "  Switched to a new branch 'llama_push'\n",
      "  Branch 'llama_push' set up to track remote branch 'llama_push' from 'origin'.\n",
      "  Resolved https://github.com/zphang/transformers to commit 3884da12ce327667d4df5101aef3533cc32be61f\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (2.28.2)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (1.26.14)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6688481 sha256=e13dd8eecdd41449d1b515efdb4d4c05bd0266247a51598bc57b09821d5c5a77\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cb97y_fi/wheels/53/e4/bb/7084176fc77631be724313d66e501b584ac58202216107b692\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.8\n",
      "    Uninstalling huggingface-hub-0.0.8:\n",
      "      Successfully uninstalled huggingface-hub-0.0.8\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.6.1\n",
      "    Uninstalling transformers-4.6.1:\n",
      "      Successfully uninstalled transformers-4.6.1\n",
      "Successfully installed huggingface-hub-0.16.4 tokenizers-0.13.3 transformers-4.27.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/zphang/transformers@llama_push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd75780a-5f5d-42ca-bd4d-a05b125c3e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 788/788 [00:00<00:00, 485kB/s]\n",
      "Downloading: 100%|██████████| 792k/792k [00:00<00:00, 77.3MB/s]\n",
      "Downloading: 100%|██████████| 2.42M/2.42M [00:00<00:00, 50.6MB/s]\n",
      "Downloading: 100%|██████████| 2.20k/2.20k [00:00<00:00, 813kB/s]\n",
      "Downloading: 100%|██████████| 2.54k/2.54k [00:00<00:00, 1.05MB/s]\n",
      "Downloading: 100%|██████████| 1.57G/1.57G [00:27<00:00, 56.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llm-blender/gen_fuser_770m\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"llm-blender/gen_fuser_770m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb8c02-f88b-4ed5-9797-f93af55061ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d835af-d1d4-4858-a704-311f0bea1ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: The project is to develop a tool to easily summarize and display the transcripts of meeting proceedings...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "## Represents displaying the output in the way we need\n",
    "def get_outputs(sample_outputs, tokenizer):\n",
    "    ## Represents taking in a tokenizer, and raw output from the given model, decoding and \n",
    "    ## formatting the output nicely\n",
    "    rt = []\n",
    "    print(\"Output:\\n\" + 100 * '-')\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        txt = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "        print(\"{}: {}...\".format(i, txt))\n",
    "        print('')\n",
    "        rt.append(txt)\n",
    "    return rt\n",
    "\n",
    "## Setting the seed helps us ensure reproducibility, and when the seed is consistent, the model outputs will be consistent\n",
    "set_seed(42)\n",
    "\n",
    "# Initialize the question or prompt\n",
    "question = \"What is the project about?\"\n",
    "\n",
    "text = \"Madhur is working on a project and he wants to be able to take the transcripts of a meeting and be able to summarize them for the meeting attendees and then display them in the form of instructions to make meetings easier, efficient, and more effective.\"\n",
    "\n",
    "# Combine the question and text using appropriate separators like \"[SEP]\"\n",
    "input_text = question + \" [SEP] \" + text\n",
    "\n",
    "# Tokenize the combined text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "sample_outputs = model.generate(input_ids,\n",
    "                                do_sample=True,\n",
    "                                num_return_sequences=1)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd654dbc-0d1a-4f18-b248-af894f563d9f",
   "metadata": {},
   "source": [
    "## STEP 2: FINE TUNE THE llama-2-7b Instruction Generator \n",
    "\n",
    "#### Here, we will tune the model on a real experiment done where I used myself to generate a meeting transcript, to check how the model performs on the transcript:\n",
    "\n",
    "#### GOALS:\n",
    "\n",
    "1. Posting instructions based on the meeting notes given\n",
    "\n",
    "2. Making sure all important points have been come across to the reader (maybe we assign labels to the meeting)\n",
    "\n",
    "3. Make sure the model uses the label to pick up the important pointers from the meeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec18605-f089-4669-a164-1158ea43645e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.txt\n",
    "\n",
    "Madhur: Hey, how's it going? So let me turn on the transcript uh language preference. Let's go with English for now. OK. \n",
    "So I can see that the machine generated captions are by Amazon transcribe. Well, this is the first time I'm joining \n",
    "Amazon Shine with my hair all open. Usually during my workout, I tie, tie them back because it just looks uh I look like a broccoli. \n",
    "But anyways, uh this is an experiment. So I'm trying to uh this, I'm trying to work on a project where for every meeting, I'm trying to \n",
    "extract the transcripts through the chime calls and then display it after the calls have ended or the meetings have ended to the uh \n",
    "members of the meeting in a summarized manner or in a manner where they feel comfortable to read. Maybe they feel like being more organized \n",
    "after they missed a huge meeting. So they just want to look at the, the important pointers. So I will be focusing on taking this transcript and \n",
    "actually using it in the prototype that I'm trying to create. And let's see how it goes. I'm trying to see if I can get this transcript really long \n",
    "so that I can see that my protype works or not. And I'm just looking at the transcripts right now because I'm just kind of distracted at how Amazon\n",
    "chime also has a one second delay, maybe a millisecond delay in their um meeting. So I can see my lips moving a bit slower than they actually are. \n",
    "So, so, yeah, a lot of redundant information there. Let's move on forward and uh, try this transcript out. All right. See you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cafa6bc8-991e-42b7-9f6f-7f507315cb01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "## Represents going over the training transcript sample above\n",
    "\n",
    "with open('train.txt') as f:\n",
    "    for row in f.readlines():\n",
    "        d = row.strip()\n",
    "        if len(d) > 0:\n",
    "            data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7feb6770-d29a-403d-b220-d06012880735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train.txt to s3://sagemaker-us-east-1-988564344122/llm/train.txt\n"
     ]
    }
   ],
   "source": [
    "## Represents importing the sagemaker role\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "train_file_name1 = 'train.txt'\n",
    "s3_train_data = 's3://{}/llm/{}'.format(bucket, train_file_name1)\n",
    "\n",
    "!aws s3 cp {train_file_name1} {s3_train_data}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad6df24-097f-4e88-9ecd-55f8c2ad88f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.175.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.28.20)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.18.6)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.20 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.20)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.10.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2022.7.1)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.20->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (2.175.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.18.6)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.28.20)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.8/site-packages (from sagemaker) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.20 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.20)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (0.9.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (5.10.2)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.8/site-packages (from jsonschema->sagemaker) (1.3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker) (2022.7.1)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.8/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.20->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker\n",
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23628c5-591b-4c7f-9053-d0a279ca684f",
   "metadata": {},
   "source": [
    "## STEP 4: TESTING OUR TRAINED MODEL LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b74b1c-86c9-4805-a49b-26184451e0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "import time\n",
    "\n",
    "try:\n",
    "    s3_model_data = huggingface_estimator.model_data\n",
    "    local_model_path = 'gen_fuser_770m'\n",
    "    \n",
    "except:\n",
    "    time.sleep(5)\n",
    "    s3_model_data = huggingface_estimator.model_data\n",
    "    local_model_path = 'gen_fuser_770m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a016c09-94b6-43d6-af39-8262f6d61ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.8/site-packages (4.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (2.28.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (23.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /opt/conda/lib/python3.8/site-packages (from transformers[torch]) (1.12.1+cpu)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[torch]) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[torch]) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[torch]) (3.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba8b9595-0160-49a1-a003-3377d32be86b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.8/site-packages (from accelerate) (1.12.1+cpu)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec891902-c1fd-4b85-b508-aa08e769d1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.31.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.12.1+cpu)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (0.13.1+cpu)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.8/site-packages (0.12.1+cpu)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch torchvision torchaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba3d4fdc-906d-41b2-ad02-2cd389f9da2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-16503248374c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m## Represents giving out the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgeneric_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "## Setting the seed helps us ensure reproducibility, and when the seed is consistent, the model outputs will be consistent\n",
    "set_seed(42)\n",
    "\n",
    "# Initialize the question or prompt\n",
    "question = \"What is the project about and what does madhur have to do?\"\n",
    "\n",
    "text = \"Madhur is working on a project and he wants to be able to take the transcripts of a meeting and be able to summarize them for the meeting attendees and then display them in the form of instructions to make meetings easier, efficient, and more effective.\"\n",
    "\n",
    "# Combine the question and text using appropriate separators like \"[SEP]\"\n",
    "input_text = question + \" [SEP] \" + text\n",
    "\n",
    "# Tokenize the combined text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "sample_outputs = model.generate(input_ids,\n",
    "                                do_sample=True,\n",
    "                                num_return_sequences=1)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8e721-6991-4966-99a4-bcd2b6696edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
