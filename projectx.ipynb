{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2bf18a7-f73d-42f8-93e1-c30b0e86a69e",
   "metadata": {},
   "source": [
    "## projectX\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "Currently, the appsec team has done good job in creating a knowledgeable for frequently asked question from service team. So, whenever a service team reach out to Individual security team member individually or in a slack group with a question that exist in the knowledge base(that security team maintains). Security team do a manual cross reference for that question in the quip doc and respond to the service team in slack with an answer. The process is good in a way that the security team doesn’t need to spend time looking out for answer for the question if it exists. However, the process of responding to service team member is still manual. It requires security team member attention and a context switch from what they currently work upon to respond to the question which has been responded earlier.\n",
    "\n",
    "\n",
    "\n",
    "#### Proposed Solution\n",
    "\n",
    "Security team is coming up with a solution which can automate and help answer the frequently asked questions from service team. There is reliance on the knowledge base and if the answer to a question exists in the knowledge base we inherently assume that the question has been asked earlier. \n",
    "\n",
    "*Note*: Process of building knowledge base is currently out of scope of this project. There is already work going on maturing the knowledge base. This project will leverage the KB to automate the response of a frequently asked question by service team in a slack message.\n",
    "\n",
    "#### STEPS:\n",
    "\n",
    "1. Build, train and deploy the model from the HuggingFace pretrained model library.\n",
    "\n",
    "2. Create a knowledge base to fine tune a pretrained model from hugging face\n",
    "\n",
    "3. Use the finetuned model to generate text responses to questions by customers.\n",
    "\n",
    "#### AI/ML solution by: Madhur Prashant (Alias: madhurpt, madhurpt@amazon.com)\n",
    "\n",
    "## Retrieval Augmented Generation (RAG) with Lanchain\n",
    "\n",
    "1. Langchain: Framework for orchestrating the RAG Workflow\n",
    "2. FAISS: Using an in-memory vector database for storing document embeddings\n",
    "3. PyPDF: Python library for processing and storing the PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f00955-c767-4ec5-8cf3-0fe59e3ee7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.251 --quiet --root-user-action=ignore\n",
    "%pip install faiss-cpu==1.7.4 --quiet --root-user-action=ignore\n",
    "%pip install pypdf==3.15.1 --quiet --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a3417-1848-4158-8a25-f7f946335d54",
   "metadata": {},
   "source": [
    "### FETCHING AND PROCESSING THE AppSec Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd61df8-639d-49bc-b105-57536d1d4e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    'Data.pdf',\n",
    "    'NYC Data.pdf',\n",
    "]\n",
    "\n",
    "data_root = \"./job_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f1848a-0946-4b1c-b28b-abfd9822ba41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Document Pages: 193\n",
      "Number of Document Chunks: 1070\n"
     ]
    }
   ],
   "source": [
    "filenames = [\n",
    "    'Data.pdf',\n",
    "    'NYC Data.pdf',\n",
    "]\n",
    "\n",
    "data_root = \"./job_data/\"\n",
    "\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in filenames:\n",
    "    loader = PyPDFLoader(data_root + filename)\n",
    "    loaded_documents = loader.load()  # Use a variable to store loaded documents\n",
    "    documents.extend(loaded_documents)  # Extend the list with loaded documents\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'Number of Document Pages: {len(documents)}')\n",
    "print(f'Number of Document Chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c36c07-c8bb-4a98-affc-6c0ed429d5fc",
   "metadata": {},
   "source": [
    "### Now, that we have processed the document or data, let's work with the model to embed the documents in vector stores to be able to use RAG to get the contextually correct AppSec related documents\n",
    "\n",
    "## Deploying a Model for Embedding: All MiniLML6 v2 and the LLaMa-2-7b-chat for our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c22367-9375-4bb0-913e-bc0893d0fffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.15.0 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.0a7 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "    sagemaker \\\n",
    "    pinecone-client==2.2.1 \\\n",
    "    ipywidgets==7.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c0e86e6-350a-43c3-923a-86d43de7a758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting urllib3==1.26.6\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m322.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install urllib3==1.26.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d8afb-036a-4237-8a4d-b1115df8482d",
   "metadata": {},
   "source": [
    "To begin, we will initialize all of the SageMaker session variables we'll need to use throughout the walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5881349-b263-4143-8e25-034a3cf3351e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "my_model = JumpStartModel(model_id = \"meta-textgeneration-llama-2-7b-f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1d2a4-b05d-4ee0-b7bf-e2c87b46a2f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LLaMa chat LLM endpoint: arn:aws:sagemaker:us-east-1:110011534045:endpoint-config/llama-2-generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d950707-3569-4d43-8e5a-f687aa147127",
   "metadata": {},
   "source": [
    "## Deploying the model endpoint for Sentence Transformer embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295653ef-0f2f-4d5a-9f81-8b035def79ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hub_config = {\n",
    "#     \"HF_MODEL_ID\": \"sentence-transformers/all-MiniLM-L6-v2\",  # model_id from hf.co/models\n",
    "#     \"HF_TASK\": \"feature-extraction\",\n",
    "# }\n",
    "\n",
    "# huggingface_model = HuggingFaceModel(\n",
    "#     env=hub_config,\n",
    "#     role=role,\n",
    "#     transformers_version=\"4.6\",  # transformers version used\n",
    "#     pytorch_version=\"1.7\",  # pytorch version used\n",
    "#     py_version=\"py36\",  # python version of the DLC\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b132d2a-7237-4838-b1a8-4b9c4bf7de78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"*\"\n",
    "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
    "embedding_predictor = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bcf0b5f-ddc6-4058-9986-d5c0db0a6db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hf-textembedding-all-minilm-l6-v2-2023-09-12-14-03-33-828'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
    "embedding_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ebdfe3-e09f-48ba-be85-e26c453571c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "print(aws_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da5a52-e599-449e-a001-a6a3c9296035",
   "metadata": {},
   "source": [
    "## Creating and Populating our Vector Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d924b28-9091-4d58-8e61-69f0103cf3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "import json\n",
    "\n",
    "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        embeddings = response_json.get(\"embedding\", [])  # Use get() with a default value\n",
    "        return embeddings  # Make sure to return the embeddings\n",
    "    \n",
    "\n",
    "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings(\n",
    "    endpoint_name= embedding_model_endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    content_handler=embeddings_content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffa506-6579-49ef-8704-a91c940d3c14",
   "metadata": {},
   "source": [
    "Now, with our embeddings, we can process our document chunks into vectors and actually store them somewhere. Our project will use the:\n",
    "\n",
    "#### FAISS: In-Memory vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d321bbaf-bc67-4696-bec4-4f154291b123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21c3c446-1bc2-4352-9b67-e69d71aee487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4b99b-f0a8-4c84-9931-444d9047c194",
   "metadata": {},
   "source": [
    "#### Now, we will store our FAISS database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b44801c9-919a-4e01-8c4a-c57f170e4bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2da94-a63c-4f2d-ad10-116fed4639fd",
   "metadata": {},
   "source": [
    "### NOW, RUNNING VECTOR QUERIES!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d64dcf43-be7b-43f6-b751-de443910f685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"data jobs in NYC?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "622bb635-5f35-48e2-a53c-cfa15011f134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: business\n",
      "goals.\n",
      "Responsibilities\n",
      "Job\n",
      "Description:\n",
      "●\n",
      "Designing\n",
      "and\n",
      "implementing\n",
      "data\n",
      "pipelines\n",
      "●\n",
      "Managing\n",
      "data\n",
      "st or age\n",
      "and\n",
      "r etrie v al\n",
      "●\n",
      "Building\n",
      "data\n",
      "war ehouses\n",
      "and\n",
      "data\n",
      "lak es\n",
      "●\n",
      "Cr eating\n",
      "and\n",
      "maintaining\n",
      "data\n",
      "APIs\n",
      "●\n",
      "Ensuring\n",
      "data\n",
      "quality\n",
      "and\n",
      "security\n",
      "●\n",
      "Sta ying\n",
      "up-t o-date\n",
      "with\n",
      "emer ging\n",
      "technologies\n",
      "K nowledge/experience,\n",
      "Skills,\n",
      "Ability\n",
      "&\n",
      "A ttitude\n",
      "●\n",
      "1-5\n",
      "y ears’\n",
      "experience\n",
      "in\n",
      "P ython,\n",
      "SQL\n",
      "ser v er ,\n",
      "Data\n",
      "modeling,\n",
      "E TL\n",
      "t ools\n",
      "or\n",
      "A WS\n",
      "Stack\n",
      "●\n",
      "Experience\n",
      "working\n",
      "with\n",
      "data\n",
      "pr ocessing\n",
      "t ools\n",
      "and\n",
      "Score 0.9199874401092529\n",
      "\n",
      "\n",
      "Content: rule,\n",
      "or\n",
      "r egulation.\n",
      "Data\n",
      "Engineer\n",
      "LMI\n",
      "·\n",
      "New\n",
      "York\n",
      "County,\n",
      "NY\n",
      "(Hybrid)\n",
      "Reposted\n",
      "1\n",
      "week\n",
      "ago\n",
      "·\n",
      "363\n",
      "applicants\n",
      "●\n",
      "Full-time\n",
      "·\n",
      "Entry\n",
      "level\n",
      "●\n",
      "1,001-5,000\n",
      "employees\n",
      "·\n",
      "Business\n",
      "Consulting\n",
      "and\n",
      "Services\n",
      "●\n",
      "4\n",
      "school\n",
      "alumni\n",
      "work\n",
      "here\n",
      "●\n",
      "Skills:\n",
      "Data\n",
      "Engineering,\n",
      "Communication,\n",
      "+8\n",
      "more\n",
      "●\n",
      "View\n",
      "verifications\n",
      "related\n",
      "to\n",
      "this\n",
      "job\n",
      "post.\n",
      "●\n",
      "View\n",
      "verifications\n",
      "related\n",
      "to\n",
      "this\n",
      "job\n",
      "post.\n",
      "●\n",
      "Show\n",
      "all\n",
      "Apply\n",
      "Save\n",
      "Score 0.9341291189193726\n",
      "\n",
      "\n",
      "Content: options\n",
      "Data\n",
      "Infr astructur e\n",
      "Engineer ,\n",
      "Google\n",
      "Cust omer\n",
      "Solutions\n",
      "Google\n",
      "New\n",
      "Y ork,\n",
      "N Y\n",
      "On-site\n",
      "Apply\n",
      "Sa v e\n",
      "Sa v e\n",
      "Data\n",
      "Infr astructur e\n",
      "Engineer ,\n",
      "Google\n",
      "Cust omer\n",
      "Solutions\n",
      "at\n",
      "Google\n",
      "Show\n",
      "mor e\n",
      "options\n",
      "About\n",
      "the\n",
      "job\n",
      "This\n",
      "r ole\n",
      "ma y\n",
      "also\n",
      "be\n",
      "located\n",
      "in\n",
      "our\n",
      "Pla y a\n",
      "Vista,\n",
      "CA\n",
      "campus.\n",
      "Note:\n",
      "By\n",
      "applying\n",
      "t o\n",
      "this\n",
      "position\n",
      "y ou\n",
      "will\n",
      "ha v e\n",
      "an\n",
      "oppor tunity\n",
      "t o\n",
      "shar e\n",
      "y our\n",
      "pr ef err ed\n",
      "working\n",
      "location\n",
      "fr om\n",
      "the\n",
      "following:\n",
      "San\n",
      "F r ancisco,\n",
      "CA,\n",
      "USA;\n",
      "New\n",
      "Y ork,\n",
      "N Y ,\n",
      "USA;\n",
      "Redwood\n",
      "City ,\n",
      "CA,\n",
      "USA;\n",
      "Ann\n",
      "Arbor ,\n",
      "MI,\n",
      "Score 0.9710981845855713\n",
      "\n",
      "\n",
      "Content: W e\n",
      "ar e\n",
      "looking\n",
      "for\n",
      "a\n",
      "Data\n",
      "Analyst\n",
      "Engineer\n",
      "t o\n",
      "join\n",
      "our\n",
      "client' s\n",
      "data\n",
      "team.\n",
      "As\n",
      "a\n",
      "Data\n",
      "Analyst\n",
      "Engineer ,\n",
      "y ou\n",
      "will\n",
      "pla y\n",
      "a\n",
      "k e y\n",
      "r ole\n",
      "in\n",
      "tr ansforming\n",
      "r aw\n",
      "data\n",
      "int o\n",
      "v aluable\n",
      "insights\n",
      "and\n",
      "actionable\n",
      "information.\n",
      "Y our\n",
      "exper tise\n",
      "in\n",
      "data\n",
      "analysis,\n",
      "database\n",
      "management,\n",
      "and\n",
      "pr ogr amming\n",
      "will\n",
      "be\n",
      "essential\n",
      "in\n",
      "driving\n",
      "data-driv en\n",
      "decision-making\n",
      "acr oss\n",
      "the\n",
      "or ganization.\n",
      "Compensation:\n",
      "$70,000.00\n",
      "–\n",
      "$80,000.00\n",
      "+\n",
      "bonus\n",
      "F or war d\n",
      "Deplo y ed\n",
      "Engineer\n",
      "C3\n",
      "AI\n",
      "·\n",
      "New\n",
      "Y ork\n",
      "City\n",
      "Municipal\n",
      "Ar chiv es,\n",
      "N Y\n",
      "(On-site)\n",
      "Score 0.9858494400978088\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}\\nScore {score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be807edd-99d3-400f-951b-c2e29e95965e",
   "metadata": {},
   "source": [
    "## PROMPT ENGINEERING FOR CUSTOM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3af26f7f-217c-40ef-813a-830bf6e76a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Use the context provided below to answer the question at the end. If you don't know the answer, please state that you don't know and do not attempt to make up an answer.\n",
    "<</SYS>>\n",
    "\n",
    "Context:\n",
    "----------------\n",
    "{context}\n",
    "----------------\n",
    "\n",
    "Question: {question} [/INST]\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad12c31-4a25-4cb4-9485-40eb3de21a2c",
   "metadata": {},
   "source": [
    "#### Now that we have defined what our prompt template is going to look like, we will create and prepare our LLM\n",
    "\n",
    "## PREPARING OUR CUSTOM LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfa95326-228a-4f79-ad5e-9db54fec3ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain import SagemakerEndpoint, PromptTemplate\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "import json\n",
    "\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            {\"inputs\" : [\n",
    "                [\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ]], \n",
    "             \"parameters\": {**model_kwargs}\n",
    "            })\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generation\"][\"content\"]\n",
    "    \n",
    "qa_content_handler = QAContentHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd094af-d0dc-4497-ac96-734edf83710e",
   "metadata": {},
   "source": [
    "Now that we have our content handler, we will deploy a sagemaker endpoint for our Large Language Model that will work with the embedding model to generate outputs.\n",
    "\n",
    "## SageMaker LLaMa-2-7b-f LLM for our CUSTOM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2be66223-48fb-480e-8638-0dcf08a5f939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "# from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"*\"\n",
    "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
    "llm_predictor = llm_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.g5.4xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baba9f1d-df41-46c2-b9f7-8f49dd695deb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-textgeneration-llama-2-7b-f-2023-09-12-14-12-21-524'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
    "llm_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "973efbe4-5503-4264-b8e7-07f28d2eb2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=llm_model_endpoint_name, \n",
    "    region_name=aws_region, \n",
    "    model_kwargs={\"max_new_tokens\": 1000, \"top_p\":0.9, \"temperature\": 1e-11}, \n",
    "    endpoint_kwargs={\"CustomAttributes\": \"accept_eula=true\"},\n",
    "    content_handler=qa_content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b329265-8dac-4722-bb4e-e026f9669e9a",
   "metadata": {},
   "source": [
    "Now, we can use our 'llm' object to query and make predictions on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc442cf0-45f1-4473-a089-245142dbac59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hello\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "409feaa9-5227-4bbe-9150-033d8c9d6b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As a new graduate in New York City, there are several data-related job opportunities available to you. Here are some of the most in-demand data jobs in NYC for new grads:\\n\\n1. Data Analyst: Data analysts are responsible for collecting, organizing, and analyzing data to help organizations make informed decisions. They use tools such as Excel, SQL, and Tableau to analyze data and create visualizations.\\n2. Data Scientist: Data scientists are responsible for developing and implementing machine learning models to solve complex problems. They use programming languages such as Python and R to analyze and interpret large datasets.\\n3. Data Engineer: Data engineers are responsible for designing, building, and maintaining large-scale data systems. They use technologies such as Hadoop, Spark, and AWS to process and store large datasets.\\n4. Business Intelligence Analyst: Business intelligence analysts are responsible for analyzing and interpreting data to help organizations make informed decisions. They use tools such as Power BI, Tableau, and Excel to create visualizations and reports.\\n5. Quantitative Analyst: Quantitative analysts are responsible for developing and implementing mathematical models to solve complex problems. They use programming languages such as Python and R to analyze and interpret large datasets.\\n6. Data Visualization Specialist: Data visualization specialists are responsible for creating visualizations and reports to help organizations communicate complex data insights. They use tools such as Tableau, Power BI, and D3.js to create interactive and dynamic visualizations.\\n7. Machine Learning Engineer: Machine learning engineers are responsible for developing and implementing machine learning models to solve complex problems. They use programming languages such as Python and R to analyze and interpret large datasets.\\n8. Data Architect: Data architects are responsible for designing and implementing data systems and infrastructure. They use technologies such as Hadoop, Spark, and AWS to process and store large datasets.\\n9. Big Data Engineer: Big data engineers are responsible for designing and implementing large-scale data systems. They use technologies such as Hadoop, Spark, and AWS to process and store large datasets.\\n10. Data Governance Manager: Data governance managers are responsible for ensuring that data is accurate, complete, and compliant with regulatory requirements. They use tools such as DataClarity and Collibra to manage data quality and metadata.\\n\\nSome of the top companies hiring data professionals in NYC include:\\n\\n1. IBM\\n2. Accenture\\n3. Deloitte\\n4. JPMorgan Chase\\n5. Goldman Sachs\\n6. Microsoft\\n7. Google\\n8. Amazon\\n9. Facebook\\n10. LinkedIn\\n\\nSome of the top data-related courses and certifications that can help you land a job in NYC include:\\n\\n1. Data Science with Python and R on Coursera\\n2. Data Engineering on edX\\n3. Data Visualization with Tableau on Udemy\\n4. Certified Data Scientist on Data Science Council of America (DASCA)\\n5. Certified Data Engineer on Data Engineer Certification (EDC)\\n\\nSome of the top data-related meetups and events in NYC include:\\n\\n1. NYC Data Science Meetup\\n2. NYC Machine Learning Meetup\\n3. NYC Data Science Conference\\n4. Data Science Summit\\n5. Big Data & Analytics Meetup\\n\\nOverall, there are many exciting data-related job opportunities available in NYC for new grads. By building the right skills and networking with the right people, you can increase your chances of landing a job in this field.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are data jobs in NYC for new grads?\"\n",
    "llm.predict(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1f79a-e0e2-4c56-bd3d-e9bb534cd801",
   "metadata": {},
   "source": [
    "## Not a bad answer, but we will create a Langchain CHAIN  using the RetrievalQA chain which will:\n",
    "\n",
    "1. Take a query as input\n",
    "2. Generate query embeddings\n",
    "3. Query the vector database for revelant chunks from the knowledge you supply\n",
    "4. Inject the context and original query in the Prompt Template\n",
    "5. Invoke the LLM with a completed prompt and\n",
    "6. Successfuly get the LLM Response/Completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bf0182a-a251-4810-9492-fba417c4d2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type = 'stuff',\n",
    "    retriever=db.as_retriever(), \n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs={\"prompt\":PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca30276-cf0e-4e8f-8e6c-6112cb05bf49",
   "metadata": {},
   "source": [
    "### Now that our chain has been created, we can supply queries to it and generate responses based on our source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9a80a62-b70d-41b4-a44f-caf00b47f554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are data jobs in NYC for new grads?\n",
      "\n",
      "Result:  Based on the provided context, there are several data jobs in NYC that are suitable for new grads. Here are some of the job postings that caught my attention:\n",
      "\n",
      "1. Data Engineer at Fortune - New York, NY (On-site): This job posting is for a Data Engineer role at Fortune, a leading media company. The job requires 1-5 years of experience in Python, SQL server, data modeling, and ETL tools. The salary range is $90,000-$110,000 per year.\n",
      "2. Data Scientist at Hewlett Packard Enterprise - Andover, MA (On-site): This job posting is for a Data Scientist role at Hewlett Packard Enterprise, a leading technology company. The job requires a graduate degree in a related field and 0-3 years of experience in data science. The salary range is $56,900-$130,600 per year.\n",
      "3. Data Engineer at Data Science Graduate - New York, NY (On-site): This job posting is for a Data Engineer role at Data Science Graduate, a leading data science and machine learning consulting firm. The job requires 1-5 years of experience in data engineering and data processing tools. The salary range is not specified.\n",
      "4. Data Analyst at Book and Periodical Publishing - New York, NY (On-site): This job posting is for a Data Analyst role at Book and Periodical Publishing, a leading publishing company. The job requires 1-3 years of experience in data analysis and data visualization tools. The salary range is $60,000-$80,000 per year.\n",
      "\n",
      "These are just a few examples of data jobs in NYC that are suitable for new grads. It's important to note that the salary ranges provided are based on the job postings and may vary depending on factors such as experience, qualifications, and location.\n",
      "\n",
      "Context Documents: \n",
      "page_content='rule,\\nor\\nr egulation.\\nData\\nEngineer\\nLMI\\n·\\nNew\\nYork\\nCounty,\\nNY\\n(Hybrid)\\nReposted\\n1\\nweek\\nago\\n·\\n363\\napplicants\\n●\\nFull-time\\n·\\nEntry\\nlevel\\n●\\n1,001-5,000\\nemployees\\n·\\nBusiness\\nConsulting\\nand\\nServices\\n●\\n4\\nschool\\nalumni\\nwork\\nhere\\n●\\nSkills:\\nData\\nEngineering,\\nCommunication,\\n+8\\nmore\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nShow\\nall\\nApply\\nSave' metadata={'source': './job_data/NYC Data.pdf', 'page': 94}\n",
      "\n",
      "page_content='business\\ngoals.\\nResponsibilities\\nJob\\nDescription:\\n●\\nDesigning\\nand\\nimplementing\\ndata\\npipelines\\n●\\nManaging\\ndata\\nst or age\\nand\\nr etrie v al\\n●\\nBuilding\\ndata\\nwar ehouses\\nand\\ndata\\nlak es\\n●\\nCr eating\\nand\\nmaintaining\\ndata\\nAPIs\\n●\\nEnsuring\\ndata\\nquality\\nand\\nsecurity\\n●\\nSta ying\\nup-t o-date\\nwith\\nemer ging\\ntechnologies\\nK nowledge/experience,\\nSkills,\\nAbility\\n&\\nA ttitude\\n●\\n1-5\\ny ears’\\nexperience\\nin\\nP ython,\\nSQL\\nser v er ,\\nData\\nmodeling,\\nE TL\\nt ools\\nor\\nA WS\\nStack\\n●\\nExperience\\nworking\\nwith\\ndata\\npr ocessing\\nt ools\\nand' metadata={'source': './job_data/NYC Data.pdf', 'page': 124}\n",
      "\n",
      "page_content='faith ”\\nwould\\npa y\\nt o\\na\\nnew\\nhir e,\\nor\\nfor\\na\\njob\\npr omotion,\\nor\\ntr ansf er\\nint o\\nthis\\nr ole.\\nData\\nEngineer\\nFortune\\n·\\nNew\\nYork,\\nNY\\n(On-site)\\nReposted\\n2\\nweeks\\nago\\n·\\n686\\napplicants\\n●\\n$90,000/yr\\n-\\n$110,000/yr\\n(from\\njob\\ndescription)\\n·\\nFull-time\\n·\\nEntry\\nlevel\\n●\\n201-500\\nemployees\\n·\\nBook\\nand\\nPeriodical\\nPublishing\\n●\\n4\\nschool\\nalumni\\nwork\\nhere\\n●\\nSkills:\\nData\\nModeling,\\nData\\nEngineering,\\n+8\\nmore\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nShow\\nall\\nApply\\nSave\\nSave\\nData' metadata={'source': './job_data/NYC Data.pdf', 'page': 104}\n",
      "\n",
      "page_content='Data\\nScience\\nGraduate\\nHewlett\\nPackard\\nEnterprise\\n·\\nAndover,\\nMA\\n(On-site)\\nReposted\\n1\\nweek\\nago\\n·\\n294\\napplicants\\n●\\n$56,900/yr\\n-\\n$130,600/yr\\n(from\\njob\\ndescription)\\n·\\nFull-time\\n●\\n10,001+\\nemployees\\n·\\nIT\\nServices\\nand\\nIT\\nConsulting\\n●\\n3\\nconnections\\nwork\\nhere\\n·\\n54\\ncompany\\nalumni\\nwork\\nhere\\n·\\n118\\nschool\\nalumni\\nwork\\nhere\\nApply\\nSave\\nSave\\nData\\nScience\\nGraduate\\nat\\n{:companyName}\\nShare\\nShow\\nmore\\noptions\\nAbout\\nthe\\njob\\nThis\\nr ole\\nhas\\nbeen\\ndesignated\\nas\\n‘E dge ’,\\nwhich\\nmeans\\ny ou\\nwill\\nprimarily\\nwork\\noutside\\nof\\nan\\nHPE\\noﬃce.\\nWho' metadata={'source': './job_data/Data.pdf', 'page': 7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What are data jobs in NYC for new grads?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66f3662e-14c7-4355-bc5f-d56063b1f61e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are jobs paying above 110000 dollars in NYC?\n",
      "\n",
      "Result:  Based on the information provided in the context, jobs paying above $110,000 in New York City (NYC) are:\n",
      "\n",
      "1. US Zone 2: $97,000 - $114,000\n",
      "2. US Zone 3: $86,000 - $101,000\n",
      "\n",
      "These salary ranges are for the successful applicant, and individual salaries within those ranges are determined through a wide variety of factors, including education, experience, knowledge, skills, and geography.\n",
      "\n",
      "Context Documents: \n",
      "page_content='What\\nWe\\nOffer\\nWe\\noffer\\na\\ncomprehensive\\ncompensation\\nand\\nbenefits\\npackage\\nwhere\\nyou’ll\\nbe\\nrewarded\\nbased\\non\\nyour\\nperformance\\nand\\nrecognized\\nfor\\nthe\\nvalue\\nyou\\nbring\\nto\\nthe\\nbusiness.\\nThe\\nsalary\\nrange\\nfor\\nthis\\njob\\nin\\nmost\\ngeographic\\nlocations\\nin\\nthe\\nUS\\nis\\n$126,300\\nto\\n$231,600.\\nThe\\nsalary\\nrange\\nfor\\nNew\\nYork\\nCity\\nMetro\\nArea,\\nWashington\\nState\\nand\\nCalifornia\\n(excluding\\nSacramento)\\nis\\n$151,600\\nto\\n$263,100.\\nIndividual\\nsalaries\\nwithin\\nthose\\nranges\\nare\\ndetermined\\nthrough\\na\\nwide\\nvariety\\nof\\nfactors\\nincluding\\nbut\\nnot' metadata={'source': './job_data/NYC Data.pdf', 'page': 26}\n",
      "\n",
      "page_content='may\\nbe\\nin\\nthe\\nform\\nof\\na\\nlive\\ninterview,\\neither\\nvia\\nvideo\\nor\\nin-person.\\nWhat\\nWe\\nOffer\\nWe\\noffer\\na\\ncomprehensive\\ncompensation\\nand\\nbenefits\\npackage\\nwhere\\nyou’ll\\nbe\\nrewarded\\nbased\\non\\nyour\\nperformance\\nand\\nrecognized\\nfor\\nthe\\nvalue\\nyou\\nbring\\nto\\nthe\\nbusiness.\\nThe\\nsalary\\nrange\\nfor\\nthis\\njob\\nin\\nmost\\ngeographic\\nlocations\\nin\\nthe\\nUS\\nis\\n$126,300\\nto\\n$231,600.\\nThe\\nsalary\\nrange\\nfor\\nNew\\nYork\\nCity\\nMetro\\nArea,\\nWashington\\nState\\nand\\nCalifornia\\n(excluding\\nSacramento)\\nis\\n$151,600\\nto\\n$263,100.\\nIndividual\\nsalaries\\nwithin\\nthose\\nranges' metadata={'source': './job_data/NYC Data.pdf', 'page': 29}\n",
      "\n",
      "page_content='and\\nr ecogniz ed\\nfor\\nthe\\nv alue\\ny ou\\nbring\\nt o\\nthe\\nbusiness.\\nThe\\nsalar y\\nr ange\\nfor\\nthis\\njob\\nin\\nmost\\ngeogr aphic\\nlocations\\nin\\nthe\\nUS\\nis\\n$119,900\\nt o\\n$219,800.\\nThe\\nsalar y\\nr ange\\nfor\\nNew\\nY ork\\nCity\\nMetr o\\nAr ea,\\nW ashingt on\\nState\\nand\\nCalifornia\\n(ex cluding\\nSacr ament o)\\nis\\n$143,900\\nt o\\n$249,800.\\nIndividual\\nsalaries\\nwithin\\nthose\\nr anges\\nar e\\ndetermined\\nthr ough\\na\\nwide\\nv ariety\\nof\\nfact ors\\nincluding\\nbut\\nnot\\nlimited\\nt o\\neducation,\\nexperience,\\nknowledge,\\nskills\\nand\\ngeogr aphy .\\nIn\\naddition,\\nour\\nT otal\\nRewar ds' metadata={'source': './job_data/NYC Data.pdf', 'page': 8}\n",
      "\n",
      "page_content='US\\nZ one\\n2:\\n$97000\\n-\\n$114000\\nUS\\nZ one\\n3:\\n$86000\\n-\\n$101000\\nBase\\npa y\\nfor\\nthe\\nsuccessful\\napplicant\\nwill\\ndepend\\non\\na\\nv ariety\\nof\\njob-r elated\\nfact ors,\\nwhich\\nma y\\ninclude\\neducation,\\ntr aining,\\nexperience,\\nlocation,\\nbusiness\\nneeds,\\nor\\nmark et\\ndemands.\\nY ou\\ncan\\nview\\ncomp\\nz ones\\nfor\\nour\\nUS\\noﬃce\\nlocations\\nin\\nthe\\ntable\\nbelow .\\nF or\\nother\\nlocations\\nnot\\nlisted,\\ncompensation\\ncan\\nbe\\ndiscussed\\nwith\\ny our\\nr ecruiter\\nduring\\nthe\\ninter view\\npr ocess.\\nOﬃce\\nlocations\\n(b y\\ncomp\\nz one)\\nUS\\nZ one\\n1:\\nMenlo\\nP ark,\\nN Y C,\\nSeattle,' metadata={'source': './job_data/NYC Data.pdf', 'page': 114}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What are jobs paying above 110000 dollars in NYC?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b95406d-6476-40b4-bb9b-0157dfcb48bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you list all job postings in NYC?\n",
      "\n",
      "Result:  Based on the provided context, I can see that there are two job postings mentioned:\n",
      "\n",
      "1. Product Manager - Data Walker & Dunlop (Hybrid) in New York, United States.\n",
      "2. Experienced Associate, Data & Analytics at {:companyName} (New Grad-Rochester, NY).\n",
      "\n",
      "Both of these job postings are located in New York City.\n",
      "\n",
      "Context Documents: \n",
      "page_content='unlimited\\npaid\\ntime\\noff,\\ncompany\\nholida ys\\nand\\nr echar ge\\nda ys,\\ncommuter\\nbeneﬁts,\\nlif estyle\\nstipends,\\nlearning\\nand\\nde v elopment\\nstipends,\\npatr onage,\\npar enta\\nProduct\\nManager\\n-\\nData\\nWalker\\n&\\nDunlop\\n·\\nNew\\nYork,\\nUnited\\nStates\\n(Hybrid)\\nReposted\\n2\\nweeks\\nago\\n·\\n165\\napplicants\\n●\\nFull-time\\n·\\nMid-Senior\\nlevel\\n●\\n1,001-5,000\\nemployees\\n·\\nFinancial\\nServices\\n●\\n3\\nschool\\nalumni\\nwork\\nhere\\n●\\n6\\nof\\n10\\nskills\\nmatch\\nyour\\nprofile\\n-\\nyou\\nmay\\nbe\\na\\ngood\\nfit\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nView\\nverifications' metadata={'source': './job_data/NYC Data.pdf', 'page': 17}\n",
      "\n",
      "page_content='Videos,\\n+8\\nmore\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nView\\nverifications\\nrelated\\nto\\nthis\\njob\\npost.\\n●\\nShow\\nall\\nApply\\nSave\\nSave\\nProgram\\nManagement\\n(New\\nGrad-\\nRochester,\\nNY)\\nat\\nL3Harris\\nTechnologies\\nShare\\nShow\\nmore\\noptions' metadata={'source': './job_data/Data.pdf', 'page': 4}\n",
      "\n",
      "page_content='Reposted\\n1\\nweek\\nago\\n·\\n10\\napplicants\\n●\\nFull-time\\n·\\nAssociate\\n●\\n10,001+\\nemployees\\n·\\nProfessional\\nServices\\n●\\n10\\nconnections\\nwork\\nhere\\n·\\n99\\ncompany\\nalumni\\nwork\\nhere\\n·\\n639\\nschool\\nalumni\\nwork\\nhere\\nApply\\nSave\\nSave\\nExperienced\\nAssociate,\\nData\\n&\\nAnalytics\\nat\\n{:companyName}\\nShare\\nShow\\nmore\\noptions' metadata={'source': './job_data/NYC Data.pdf', 'page': 41}\n",
      "\n",
      "page_content='(New\\nGr ad\\n-\\nRochester ,\\nN Y )\\nL3Harris\\nT echnologies\\nRochester ,\\nN Y\\nOn-site\\nApply\\nSa v e\\nSa v e\\nPr oduct\\nManagement\\n(New\\nGr ad\\n-\\nRochester ,\\nN Y )\\nat\\nL3Harris\\nT echnologies\\nShow\\nmor e\\noptions\\nAbout\\nthe\\njob\\nDescription:\\nJob\\nTitle:\\nPr oduct\\nManagement\\n(New\\nGr ad\\n-\\nRochester ,\\nN Y )\\nJob\\nCode:\\nCS20230706-101976\\nJob\\nLocation:\\nRochester ,\\nN Y\\nJob\\nDescription:\\n●\\nThis\\nmission\\ncritical\\nposition\\nwill\\nwork\\non\\nthe\\nPr oduct\\nLine\\nManagement\\nteams.' metadata={'source': './job_data/Data.pdf', 'page': 12}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you list all job postings in NYC?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f'Query: {result[\"query\"]}\\n')\n",
    "print(f'Result: {result[\"result\"]}\\n')\n",
    "print(f'Context Documents: ')\n",
    "for srcdoc in result[\"source_documents\"]:\n",
    "    print(f'{srcdoc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94fbfc-6946-4a84-a0ca-bd65222cc5a8",
   "metadata": {},
   "source": [
    "## CLEAN UP YOUR ENDPOINT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a984025-312b-4d56-b3d4-997a448cd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "\n",
    "# sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n",
    "# sagemaker_client.delete_endpoint(EndpointName=llm_model_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
