{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27100626-4aa0-455a-bb3b-69f30555c3e3",
   "metadata": {},
   "source": [
    "# Meeting Notes Summarizer: AWS Summarize\n",
    "\n",
    "### This code represents using SageMaker, and HuggingFace, to summarize the transcripts from a given meeting, and organizing them for further reference.\n",
    "\n",
    "## GOALS:\n",
    "\n",
    "#### Integrate one of the HuggingFace pretrained models, that we will fine tune based on a lot of self created data, and then build and deploy. \n",
    "\n",
    "#### STEPS:\n",
    "\n",
    "1. Build, train and deploy the model from the HuggingFace pretrained model library.\n",
    "\n",
    "2. Leverage self recordings from Chime, with all of the transcripts stored in the s3 bucket that we will use for reference and training.\n",
    "\n",
    "3. Use the trained model to create an efficient notes organizer for AWS employees and meeting members.\n",
    "\n",
    "#### Integrate a Speech to text converter to convert speech and points from different speakers in the meeting in a live document for our model to refer to and train our data on.\n",
    "\n",
    "## STEP 0: INSTALL THE TRANSFORMERS SDK LOCALLY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876e9d42-254c-47ce-9303-707e6c1cafd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "transformers == 4.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9000bf1a-6b68-47e3-a2a7-84c63dc84ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import IPython\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "IPython.Application.instance().kernel.do_shutdown(True)  # has to restart kernel so changes are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8718bfb-dadb-4bf4-90db-5985233a4660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.6.1\n",
      "  Using cached transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (21.3)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (1.22.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->transformers==4.6.1->-r requirements.txt (line 2)) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.6.1->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (8.0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (1.1.0)\n",
      "Installing collected packages: tokenizers, regex, filelock, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 huggingface-hub-0.0.8 regex-2023.6.3 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## Represents installing the requirements for this model\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd4c89-6aea-49a5-85d7-407d75a0cd5b",
   "metadata": {},
   "source": [
    "## STEP 1: DOWNLOAD A PRETRAINED FACEBOOK BART MODEL AND TEST IT LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7259625a-6c88-429b-b209-5ed2eb20487b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.0)\n",
      "Requirement already satisfied: widgetsnbextension in /opt/conda/lib/python3.8/site-packages (4.0.8)\n",
      "Collecting pandas-profiling\n",
      "  Using cached pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.0.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.1.3)\n",
      "Collecting ydata-profiling\n",
      "  Using cached ydata_profiling-4.4.0-py2.py3-none-any.whl (356 kB)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (60.9.3)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (3.0.3)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Using cached visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (0.11.2)\n",
      "Collecting dacite>=1.8\n",
      "  Using cached dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Collecting multimethod<2,>=1.4\n",
      "  Using cached multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Collecting imagehash==4.3.1\n",
      "  Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (2.27.1)\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Using cached phik-0.12.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
      "Collecting statsmodels<1,>=0.13.2\n",
      "  Using cached statsmodels-0.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Collecting wordcloud>=1.9.1\n",
      "  Using cached wordcloud-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Collecting pydantic<2,>=1.8.1\n",
      "  Using cached pydantic-1.10.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (1.4.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (1.22.2)\n",
      "Collecting htmlmin==0.1.12\n",
      "  Using cached htmlmin-0.1.12-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib<4,>=3.2 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (3.5.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (4.62.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (5.4.1)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from ydata-profiling->pandas-profiling) (1.8.0)\n",
      "Collecting typeguard<3,>=2.13.2\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (9.0.1)\n",
      "Collecting PyWavelets\n",
      "  Using cached PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (20.3.0)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Using cached tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "Collecting networkx>=2.4\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (4.29.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas-profiling) (3.0.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas!=1.4.0,<2.1,>1.1->ydata-profiling->pandas-profiling) (2021.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.8/site-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.1.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.4)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (8.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.4.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (0.9.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets) (2.5.1)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (1.16.0)\n",
      "Installing collected packages: htmlmin, typing-extensions, typeguard, tangled-up-in-unicode, PyWavelets, patsy, networkx, multimethod, dacite, pydantic, imagehash, wordcloud, visions, statsmodels, phik, ydata-profiling, pandas-profiling\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.1.1\n",
      "    Uninstalling typing_extensions-4.1.1:\n",
      "      Successfully uninstalled typing_extensions-4.1.1\n",
      "Successfully installed PyWavelets-1.4.1 dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.9.1 networkx-3.1 pandas-profiling-3.6.6 patsy-0.5.3 phik-0.12.3 pydantic-1.10.12 statsmodels-0.14.0 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 typing-extensions-4.7.1 visions-0.7.5 wordcloud-1.9.2 ydata-profiling-4.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets widgetsnbextension pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1138416a-f5c7-49d0-bfa1-67e741f60793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006663322448730469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1585,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ebddf1e6c14bcda5759def8d71d078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008899211883544922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 898823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c716cbd5ca4fecafb7beca3792c16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007265567779541016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e0ff62d8cb4723bfc3701153193c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00676727294921875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1355863,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05289f995f3c4dd09b335dba1ebe9dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009614229202270508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1625270765,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79c5480d41144e7938b4c763549882e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "notes_gpt = \"facebook/bart-large-cnn\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(notes_gpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(notes_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc47e36-def2-49db-b42e-f3ea706307e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: Karen decided she’d finally do something about all the negative comments. She colored her hair, bought a pair of honest-to-goodness jeans, and changed her name to Kathy. Upon leaving the Social Security Administration, she spied a couple arguing heatedly about what their married last name ought to be. Kathy couldn’t stand to see and hear such animosity between two people in love, and walked toward them. Before she could even open her mouth, however, the woman turned to her and said, “Butt out, Karen!”...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "## Represents displaying the output in the way we need\n",
    "def get_outputs(sample_outputs, tokenizer):\n",
    "    \n",
    "    ## Represents taking in a tokenizer, and raw output from the given model, decoding and \n",
    "    ## formatting the output nicely\n",
    "    rt = []\n",
    "    \n",
    "    print(\"Output:\\n\" + 100 * '-')\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        txt = tokenizer.decode(sample_output, skip_special_tokens = True)\n",
    "        print(\"{}: {}...\".format(i, txt))\n",
    "        print('')\n",
    "        rt.append(txt)\n",
    "        \n",
    "    return rt\n",
    "\n",
    "## Setting the seed helps us ensure reproducibility, and when the seed is consistent, the model outputs will be consistent\n",
    "set_seed(42)\n",
    "\n",
    "text = \"Karen hadn’t asked to be named Karen. She hadn’t asked to be dressed in modest dresses, always with tights and shoes. She certainly hadn’t asked for her parents to use the sort of psychological conditioning that led to so many people saying, “Butt out, Karen!” Once Mom and Dad passed away, Karen decided she’d finally do something about all the negative comments. She colored her hair, bought a pair of honest-to-goodness jeans, and changed her name to Kathy. Upon leaving the Social Security Administration, she spied a couple arguing heatedly about what their married last name ought to be. Kathy couldn’t stand to see and hear such animosity between two people in love, and walked toward them. Before she could even open her mouth, however, the woman turned to her and said, “Butt out, Karen!”.\"\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors = 'pt')\n",
    "\n",
    "sample_outputs = model.generate(input_ids, \n",
    "                                     do_sample = True, \n",
    "                                     ##max_length = 90,\n",
    "                                     num_return_sequences = 1)\n",
    "\n",
    "## Represents giving out the output\n",
    "generic_outputs = get_outputs(sample_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a2ee5-073c-44e0-867b-77436e79116b",
   "metadata": {},
   "source": [
    "## STEP 2: FINE TUNE THE FACEBOOK BART SUMMARIZER WITH A REAL MEETING TRANSCRIPT (SELF-RECORDED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83354f07-09bb-4597-adfd-d8d251744640",
   "metadata": {},
   "source": [
    "#### Here, we will tune the model on a real experiment done where I used myself to generate a meeting transcript, to check how the model performs on the transcript:\n",
    "\n",
    "#### GOALS:\n",
    "\n",
    "1. Summarizing a transcript in an organized way\n",
    "\n",
    "2. Making sure all important points have been come across to the reader (maybe we assign labels to the meeting)\n",
    "\n",
    "3. Make sure the model uses the label to pick up the important pointers from the meeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aec0a7eb-0ca0-47ba-a8d9-3ae436f1ca30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.txt\n",
    "\n",
    "Madhur: Hey, how's it going? So let me turn on the transcript uh language preference. Let's go with English for now. OK. \n",
    "So I can see that the machine generated captions are by Amazon transcribe. Well, this is the first time I'm joining \n",
    "Amazon Shine with my hair all open. Usually during my workout, I tie, tie them back because it just looks uh I look like a broccoli. \n",
    "But anyways, uh this is an experiment. So I'm trying to uh this, I'm trying to work on a project where for every meeting, I'm trying to \n",
    "extract the transcripts through the chime calls and then display it after the calls have ended or the meetings have ended to the uh \n",
    "members of the meeting in a summarized manner or in a manner where they feel comfortable to read. Maybe they feel like being more organized \n",
    "after they missed a huge meeting. So they just want to look at the, the important pointers. So I will be focusing on taking this transcript and \n",
    "actually using it in the prototype that I'm trying to create. And let's see how it goes. I'm trying to see if I can get this transcript really long \n",
    "so that I can see that my protype works or not. And I'm just looking at the transcripts right now because I'm just kind of distracted at how Amazon\n",
    "chime also has a one second delay, maybe a millisecond delay in their um meeting. So I can see my lips moving a bit slower than they actually are. \n",
    "So, so, yeah, a lot of redundant information there. Let's move on forward and uh, try this transcript out. All right. See you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5048d1-c92c-49e8-b108-c0ad7798317d",
   "metadata": {},
   "source": [
    "#### We are going to use a script written by hunning face: run CLM that sits on the Hugging Face repo and we can pass in generic text (we do not have to tokenize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e928c5-556a-4888-9bd5-0c841d3732cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "## Represents going over the training transcript sample above\n",
    "\n",
    "with open('train.txt') as f:\n",
    "    for row in f.readlines():\n",
    "        d = row.strip()\n",
    "        if len(d) > 0:\n",
    "            data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2e660cf-d639-4ad2-97c1-0046ffe2d7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Madhur: Hey, how's it going? So let me turn on the transcript uh language preference. Let's go with English for now. OK.\", \"So I can see that the machine generated captions are by Amazon transcribe. Well, this is the first time I'm joining\", 'Amazon Shine with my hair all open. Usually during my workout, I tie, tie them back because it just looks uh I look like a broccoli.', \"But anyways, uh this is an experiment. So I'm trying to uh this, I'm trying to work on a project where for every meeting, I'm trying to\", 'extract the transcripts through the chime calls and then display it after the calls have ended or the meetings have ended to the uh', 'members of the meeting in a summarized manner or in a manner where they feel comfortable to read. Maybe they feel like being more organized', 'after they missed a huge meeting. So they just want to look at the, the important pointers. So I will be focusing on taking this transcript and', \"actually using it in the prototype that I'm trying to create. And let's see how it goes. I'm trying to see if I can get this transcript really long\", \"so that I can see that my protype works or not. And I'm just looking at the transcripts right now because I'm just kind of distracted at how Amazon\", 'chime also has a one second delay, maybe a millisecond delay in their um meeting. So I can see my lips moving a bit slower than they actually are.']\n"
     ]
    }
   ],
   "source": [
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "075144e7-c409-4a74-8635-93f726be7f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./train.txt to s3://sagemaker-us-east-1-988564344122/bart/train.txt\n"
     ]
    }
   ],
   "source": [
    "## Represents importing the sagemaker role\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "train_file_name = 'train.txt'\n",
    "s3_train_data = 's3://{}/bart/{}'.format(bucket, train_file_name)\n",
    "\n",
    "!aws s3 cp {train_file_name} {s3_train_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31c32f1a-20d0-4631-adf1-ba24e6350441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Source directory does not exist in the repo.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0c5c9366920b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# starting the train job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mhuggingface_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_train_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipelineSession\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m-> 1246\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mexperiment_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_and_get_run_experiment_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   3209\u001b[0m                 \u001b[0mconstructor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mapplicable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m         \"\"\"\n\u001b[0;32m-> 3211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFramework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_and_set_debugger_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             updated_paths = git_utils.git_clone_repo(\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             )\n\u001b[1;32m    821\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdated_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entry_point\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/git_utils.py\u001b[0m in \u001b[0;36mgit_clone_repo\u001b[0;34m(git_config, entry_point, source_dir, dependencies)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Source directory does not exist in the repo.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Entry point does not exist in the repo.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Source directory does not exist in the repo."
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\t\t\n",
    "hyperparameters = {\n",
    "\t'model_name_or_path':'facebook/bart-large-cnn',\n",
    "\t'output_dir':'/opt/ml/model',\n",
    "    'do_train':True,\n",
    "    'train_file': '/opt/ml/input/data/train/{}'.format(train_file_name),\n",
    "    'num_train_epochs': 5, \n",
    "    \"per_device_train_batch_size\": 64,\n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.26.0/examples/pytorch/seq2seq\n",
    "}\n",
    "\n",
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.26.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "\tentry_point='run_summarization.py',\n",
    "\tsource_dir='./examples/pytorch/seq2seq',\n",
    "\tinstance_type='ml.p3.2xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.26.0',\n",
    "\tpytorch_version='1.13.1',\n",
    "\tpy_version='py39',\n",
    "\thyperparameters = hyperparameters,\n",
    "    \n",
    "    ## Pass the training compiler config to speed up your job\n",
    "    ##compiler_config = TrainingCompilerConfig(), \n",
    "    environment = {'GPU_NUM_DEVICES': '1'},\n",
    "    disable_profiler = True, \n",
    "    debugger_hook_config = False\n",
    ")\n",
    "\n",
    "# starting the train job\n",
    "huggingface_estimator.fit({'train': s3_train_data}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec4580-efdc-4c32-949a-b17749c5c539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
